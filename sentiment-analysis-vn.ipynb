{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"authorship_tag":"ABX9TyMKBNv0DgMROlxH5KUikvBG"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11939197,"sourceType":"datasetVersion","datasetId":7314670}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Preparing the Dataset","metadata":{"id":"xAVF_OkQ4Bie"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:11.498157Z","iopub.execute_input":"2025-09-03T02:37:11.498451Z","iopub.status.idle":"2025-09-03T02:37:11.505208Z","shell.execute_reply.started":"2025-09-03T02:37:11.498425Z","shell.execute_reply":"2025-09-03T02:37:11.504312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport re ","metadata":{"id":"C_70PqesOxnp","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:15.144976Z","iopub.execute_input":"2025-09-03T02:37:15.145350Z","iopub.status.idle":"2025-09-03T02:37:15.150454Z","shell.execute_reply.started":"2025-09-03T02:37:15.145320Z","shell.execute_reply":"2025-09-03T02:37:15.149325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_path_1 = '/kaggle/input/vietnamese-comment/comments.csv'\ndata_path_2 = '/kaggle/input/vietnamese-comment/extra.csv' ","metadata":{"executionInfo":{"elapsed":17824,"status":"ok","timestamp":1746193805847,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"vDsAVM7jfp-F","outputId":"7fa7ea5d-243d-42dd-ba4d-0aa1065f2334","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:18.603446Z","iopub.execute_input":"2025-09-03T02:37:18.603863Z","iopub.status.idle":"2025-09-03T02:37:18.609003Z","shell.execute_reply.started":"2025-09-03T02:37:18.603832Z","shell.execute_reply":"2025-09-03T02:37:18.607779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_1 = pd.read_csv(data_path_1)\ndata_1.head()","metadata":{"executionInfo":{"elapsed":2089,"status":"ok","timestamp":1746193810496,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"7YUIE0d3P4JD","outputId":"063eac9b-2064-4ead-9129-5f9eeb8c0039","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:19.802227Z","iopub.execute_input":"2025-09-03T02:37:19.802551Z","iopub.status.idle":"2025-09-03T02:37:20.390739Z","shell.execute_reply.started":"2025-09-03T02:37:19.802530Z","shell.execute_reply":"2025-09-03T02:37:20.389377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(data_1) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:21.635244Z","iopub.execute_input":"2025-09-03T02:37:21.635696Z","iopub.status.idle":"2025-09-03T02:37:21.645048Z","shell.execute_reply.started":"2025-09-03T02:37:21.635665Z","shell.execute_reply":"2025-09-03T02:37:21.643832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_2 = pd.read_csv(data_path_2)\ndata_2.head()","metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1746193812178,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"uzkSZ0Shdzt6","outputId":"d9a7f01d-8250-4fdb-8119-f638504e4ddc","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:25.460714Z","iopub.execute_input":"2025-09-03T02:37:25.461115Z","iopub.status.idle":"2025-09-03T02:37:25.504860Z","shell.execute_reply.started":"2025-09-03T02:37:25.461081Z","shell.execute_reply":"2025-09-03T02:37:25.503541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(data_2) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:26.836858Z","iopub.execute_input":"2025-09-03T02:37:26.837191Z","iopub.status.idle":"2025-09-03T02:37:26.844120Z","shell.execute_reply.started":"2025-09-03T02:37:26.837165Z","shell.execute_reply":"2025-09-03T02:37:26.843097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data_1 = data_1.drop(columns=['title'])\n# data = pd.concat([data_1, data_2])\n\ndata = data_1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:30.342040Z","iopub.execute_input":"2025-09-03T02:37:30.342523Z","iopub.status.idle":"2025-09-03T02:37:30.347833Z","shell.execute_reply.started":"2025-09-03T02:37:30.342492Z","shell.execute_reply":"2025-09-03T02:37:30.346548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head(10) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:31.556865Z","iopub.execute_input":"2025-09-03T02:37:31.557216Z","iopub.status.idle":"2025-09-03T02:37:31.568693Z","shell.execute_reply.started":"2025-09-03T02:37:31.557190Z","shell.execute_reply":"2025-09-03T02:37:31.567367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(data) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:35.726404Z","iopub.execute_input":"2025-09-03T02:37:35.726808Z","iopub.status.idle":"2025-09-03T02:37:35.734207Z","shell.execute_reply.started":"2025-09-03T02:37:35.726778Z","shell.execute_reply":"2025-09-03T02:37:35.733094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values = data.isnull().sum()\nprint(\"Dữ liệu bị thiếu:\\n\", missing_values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:37.011839Z","iopub.execute_input":"2025-09-03T02:37:37.012235Z","iopub.status.idle":"2025-09-03T02:37:37.039799Z","shell.execute_reply.started":"2025-09-03T02:37:37.012205Z","shell.execute_reply":"2025-09-03T02:37:37.038340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"duplicates = data.duplicated(subset=[\"content\"]).sum()\nprint(\"Số câu trùng lặp:\", duplicates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:38.177368Z","iopub.execute_input":"2025-09-03T02:37:38.177728Z","iopub.status.idle":"2025-09-03T02:37:38.207756Z","shell.execute_reply.started":"2025-09-03T02:37:38.177701Z","shell.execute_reply":"2025-09-03T02:37:38.205987Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Data Preprocessing","metadata":{"id":"8ZYScp6ADQOX"}},{"cell_type":"markdown","source":"## 2.1 Data Cleaning","metadata":{"id":"LGaJuM4WD1eT"}},{"cell_type":"code","source":"# data = data.dropna(subset=[\"content\"])           # bỏ comment rỗng\ndata = data.dropna(subset=['title', 'content']) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:42.559956Z","iopub.execute_input":"2025-09-03T02:37:42.560320Z","iopub.status.idle":"2025-09-03T02:37:42.600005Z","shell.execute_reply.started":"2025-09-03T02:37:42.560292Z","shell.execute_reply":"2025-09-03T02:37:42.598283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(data)","metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1746193815494,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"6gcND-Kbd5nN","outputId":"d98cee72-c031-424a-eb30-43168952e83b","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:43.749820Z","iopub.execute_input":"2025-09-03T02:37:43.750150Z","iopub.status.idle":"2025-09-03T02:37:43.756887Z","shell.execute_reply.started":"2025-09-03T02:37:43.750125Z","shell.execute_reply":"2025-09-03T02:37:43.755438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import unicodedata","metadata":{"id":"mdpDYHzWVnK_","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:44.887710Z","iopub.execute_input":"2025-09-03T02:37:44.888040Z","iopub.status.idle":"2025-09-03T02:37:44.894670Z","shell.execute_reply.started":"2025-09-03T02:37:44.888016Z","shell.execute_reply":"2025-09-03T02:37:44.893098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dictionary for common Vietnamese slang/abbreviations\nabbreviations = {\n    \"ko\": \"không\",\n    \"sp\": \"sản phẩm\",\n    \"k\": \"không\",\n    \"m\": \"mình\",\n    \"đc\": \"được\",\n    \"dc\": \"được\",\n    \"h\": \"giờ\",\n    \"trloi\": \"trả lời\",\n    \"cg\": \"cũng\",\n    \"bt\": \"bình thường\",\n    \"dt\": \"điện thoại\",\n    \"mt\": \"máy tính\",\n    \"m.n\": \"mọi người\"\n    # add more slang mappings\n}\n\n# Regex patterns\nurl_pattern = r\"http\\S+|www\\S+\"  # URLs\nuser_pattern = r\"@\\w+\"  # usernames\nemoji_pattern = re.compile(\n    \"[\"  # start\n    \"\\U0001F600-\\U0001F64F\"  # emoticons\n    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n    \"\\U0001F1E0-\\U0001F1FF\"  # flags\n    \"]+\", flags=re.UNICODE)\nemoticon_pattern = r\"[:;=8][\\-o\\*']?[\\)\\]\\(\\[dDpP/:}\\{@\\|\\\\]\"  # emoticons\nrepeat_pattern = re.compile(r\"(.)\\1{2,}\")  # 3 or more repeats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:48.656409Z","iopub.execute_input":"2025-09-03T02:37:48.656776Z","iopub.status.idle":"2025-09-03T02:37:48.664258Z","shell.execute_reply.started":"2025-09-03T02:37:48.656749Z","shell.execute_reply":"2025-09-03T02:37:48.662686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clean_text(text: str) -> str:\n    # Unicode normalization\n    text = str(text)\n    text = unicodedata.normalize('NFC', text)  # Chuẩn hoá Unicode rõ ràng (căn bản)\n\n    # Lowercase\n    text = text.lower()\n\n    # Remove URLs and usernames\n    text = re.sub(url_pattern, '', text)\n    text = re.sub(user_pattern, '', text)\n\n    # Remove emojis and emoticons\n    text = emoji_pattern.sub(' ', text)\n    text = re.sub(emoticon_pattern, ' ', text)\n\n    # Expand common abbreviations\n    def expand(match):\n        word = match.group(0)\n        return abbreviations.get(word, word)\n\n    if abbreviations:\n        pattern = re.compile(r\"\\b(\" + \"|\".join(map(re.escape, abbreviations.keys())) + r\")\\b\")\n        text = pattern.sub(expand, text)\n\n    # Remove repeated characters (e.g., \"quaaa\" -> \"qua\" )\n    text = repeat_pattern.sub(r\"\\1\", text)\n\n    # Remove punctuation (keep Vietnamese letters & numbers)\n    text = re.sub(r\"[^\\w\\s\\u00C0-\\u024F]\", ' ', text)\n\n    # Remove extra whitespace\n    text = re.sub(r\"\\s+\", ' ', text).strip()\n\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:51.821660Z","iopub.execute_input":"2025-09-03T02:37:51.822018Z","iopub.status.idle":"2025-09-03T02:37:51.830485Z","shell.execute_reply.started":"2025-09-03T02:37:51.821991Z","shell.execute_reply":"2025-09-03T02:37:51.829375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = \"Tui thik qááá!!! 😊😊, thanks @ban http://example.com\"\nprint(clean_text(sample))  # Expected: \"tui thích qua cảm ơn\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:54.789235Z","iopub.execute_input":"2025-09-03T02:37:54.789563Z","iopub.status.idle":"2025-09-03T02:37:54.797299Z","shell.execute_reply.started":"2025-09-03T02:37:54.789542Z","shell.execute_reply":"2025-09-03T02:37:54.796182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data[\"text\"] = data[\"content\"].apply(clean_text)","metadata":{"id":"1hcGFVNdVqvk","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:37:55.907899Z","iopub.execute_input":"2025-09-03T02:37:55.908243Z","iopub.status.idle":"2025-09-03T02:37:59.992895Z","shell.execute_reply.started":"2025-09-03T02:37:55.908216Z","shell.execute_reply":"2025-09-03T02:37:59.991579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head()","metadata":{"executionInfo":{"elapsed":260,"status":"ok","timestamp":1746193819053,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"O2XJfW-dVtpQ","outputId":"55efdbe7-166a-4aec-c4b9-8e9fd1224ac0","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:04.835220Z","iopub.execute_input":"2025-09-03T02:38:04.835640Z","iopub.status.idle":"2025-09-03T02:38:04.848551Z","shell.execute_reply.started":"2025-09-03T02:38:04.835572Z","shell.execute_reply":"2025-09-03T02:38:04.847365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = data.groupby('text', as_index=False)['rating'].mean()  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:08.826102Z","iopub.execute_input":"2025-09-03T02:38:08.826466Z","iopub.status.idle":"2025-09-03T02:38:09.022507Z","shell.execute_reply.started":"2025-09-03T02:38:08.826439Z","shell.execute_reply":"2025-09-03T02:38:09.021285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['rating'] = np.floor(data['rating']).astype(int) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:10.342856Z","iopub.execute_input":"2025-09-03T02:38:10.343208Z","iopub.status.idle":"2025-09-03T02:38:10.352375Z","shell.execute_reply.started":"2025-09-03T02:38:10.343181Z","shell.execute_reply":"2025-09-03T02:38:10.350807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"duplicates = data.duplicated(subset=[\"text\"]).sum()\nprint(\"Số câu trùng lặp sau xử lý:\", duplicates) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:14.714246Z","iopub.execute_input":"2025-09-03T02:38:14.714690Z","iopub.status.idle":"2025-09-03T02:38:14.743343Z","shell.execute_reply.started":"2025-09-03T02:38:14.714659Z","shell.execute_reply":"2025-09-03T02:38:14.741891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def sentiment(r):\n    if r >= 4: return \"tích cực\"\n    if r == 3: return \"bình thường\"\n    return \"tiêu cực\"\ndef label(r):\n    if r >= 4: return 2\n    if r == 3: return 1\n    return 0\ndata[\"sentiment\"] = data[\"rating\"].apply(sentiment)\ndata[\"label\"] = data[\"rating\"].apply(label)","metadata":{"id":"vX1efgvuebd6","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:15.681136Z","iopub.execute_input":"2025-09-03T02:38:15.681543Z","iopub.status.idle":"2025-09-03T02:38:15.718463Z","shell.execute_reply.started":"2025-09-03T02:38:15.681512Z","shell.execute_reply":"2025-09-03T02:38:15.716848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head()","metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1746193821607,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"5iVRzBnqeghM","outputId":"2398a97d-ce17-45c1-d429-250f9296dea6","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:16.712126Z","iopub.execute_input":"2025-09-03T02:38:16.712512Z","iopub.status.idle":"2025-09-03T02:38:16.724378Z","shell.execute_reply.started":"2025-09-03T02:38:16.712483Z","shell.execute_reply":"2025-09-03T02:38:16.723292Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2 Statistical Analysis","metadata":{"id":"tGRmgNK5D89Q"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"id":"gv976yWHWcaA","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:21.067652Z","iopub.execute_input":"2025-09-03T02:38:21.068007Z","iopub.status.idle":"2025-09-03T02:38:21.910917Z","shell.execute_reply.started":"2025-09-03T02:38:21.067979Z","shell.execute_reply":"2025-09-03T02:38:21.909406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Số lượng mẫu:\", data.shape[0])","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1746193825497,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"VwBOfngAWf4D","outputId":"d4863a13-a29d-46ef-9ec5-776935629c8e","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:23.113454Z","iopub.execute_input":"2025-09-03T02:38:23.114753Z","iopub.status.idle":"2025-09-03T02:38:23.120844Z","shell.execute_reply.started":"2025-09-03T02:38:23.114715Z","shell.execute_reply":"2025-09-03T02:38:23.119419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nsns.countplot(x=data[\"sentiment\"], palette=\"coolwarm\")\nplt.title(\"Phân phối nhãn cảm xúc\")\nplt.xlabel(\"Cảm xúc\")\nplt.ylabel(\"Số lượng mẫu\")\nplt.show()","metadata":{"executionInfo":{"elapsed":461,"status":"ok","timestamp":1746193827036,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"iJG9XwFVWlub","outputId":"47ce09af-04be-4643-df07-c2e9975570b1","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:24.250879Z","iopub.execute_input":"2025-09-03T02:38:24.251513Z","iopub.status.idle":"2025-09-03T02:38:24.497384Z","shell.execute_reply.started":"2025-09-03T02:38:24.251463Z","shell.execute_reply":"2025-09-03T02:38:24.495898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values = data.isnull().sum()\nprint(\"Dữ liệu bị thiếu:\\n\", missing_values)","metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1746193828233,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"j3x1DPRXWpj8","outputId":"d3cf5b28-3c0e-4d11-8a1f-2a5251d9761e","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:28.235297Z","iopub.execute_input":"2025-09-03T02:38:28.236725Z","iopub.status.idle":"2025-09-03T02:38:28.255409Z","shell.execute_reply.started":"2025-09-03T02:38:28.236679Z","shell.execute_reply":"2025-09-03T02:38:28.253992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_counts = data[\"sentiment\"].value_counts()\nprint(\"Số lượng mỗi nhãn:\\n\", label_counts)","metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1746193831015,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"gvWYi5LLXZSO","outputId":"ee01d7ee-aea6-4c5c-92c4-7382a5289079","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:29.310488Z","iopub.execute_input":"2025-09-03T02:38:29.311583Z","iopub.status.idle":"2025-09-03T02:38:29.321546Z","shell.execute_reply.started":"2025-09-03T02:38:29.311546Z","shell.execute_reply":"2025-09-03T02:38:29.320210Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install underthesea ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:30.446368Z","iopub.execute_input":"2025-09-03T02:38:30.446704Z","iopub.status.idle":"2025-09-03T02:38:34.632859Z","shell.execute_reply.started":"2025-09-03T02:38:30.446680Z","shell.execute_reply":"2025-09-03T02:38:34.631451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from underthesea import word_tokenize\nimport nltk\nimport wordcloud","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:39.885966Z","iopub.execute_input":"2025-09-03T02:38:39.886368Z","iopub.status.idle":"2025-09-03T02:38:45.016088Z","shell.execute_reply.started":"2025-09-03T02:38:39.886337Z","shell.execute_reply":"2025-09-03T02:38:45.014906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['corpus'] = data['text'].map(lambda text: word_tokenize(text, format=\"text\")) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:38:46.687740Z","iopub.execute_input":"2025-09-03T02:38:46.688411Z","iopub.status.idle":"2025-09-03T02:40:28.109049Z","shell.execute_reply.started":"2025-09-03T02:38:46.688375Z","shell.execute_reply":"2025-09-03T02:40:28.108034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.sample(10) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create bag of words\n# Flatten the list of lists into a single list of words\nall_words_flat = []\nfor tokens in data['corpus'].tolist():\n    if tokens and tokens != '':\n        all_words_flat.extend(tokens.split())\n\n# Create FreqDist from the flattened list\nall_words_dist = nltk.FreqDist(all_words_flat)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print the total number of words and the 15 most common words\nprint('Tổng số từ: {}'.format(len(all_words_dist)))\nprint('Từ xuất hiện nhiều: {}'.format(all_words_dist.most_common(15)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corpus = \" \".join(all_words_flat)\nplt.figure(figsize=(12,8))\nword_cloud = wordcloud.WordCloud(max_words=100, background_color =\"black\", width=2000, height=1000, mode=\"RGB\").generate(corpus)\nplt.axis(\"off\")\nplt.imshow(word_cloud)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3 Oversampling","metadata":{"id":"_b-MYlkuEJoD"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"id":"L8qIy5ekB4I9","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:40:37.625768Z","iopub.execute_input":"2025-09-03T02:40:37.626140Z","iopub.status.idle":"2025-09-03T02:40:37.631377Z","shell.execute_reply.started":"2025-09-03T02:40:37.626111Z","shell.execute_reply":"2025-09-03T02:40:37.630305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n    data['text'],\n    data['label'],\n    test_size=0.2,\n    stratify=data['label'],\n    random_state=42\n)","metadata":{"id":"eeAd3GCb-GkT","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:43:10.771307Z","iopub.execute_input":"2025-09-03T02:43:10.771710Z","iopub.status.idle":"2025-09-03T02:43:10.806463Z","shell.execute_reply.started":"2025-09-03T02:43:10.771681Z","shell.execute_reply":"2025-09-03T02:43:10.805476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:41:58.401005Z","iopub.execute_input":"2025-09-03T02:41:58.401401Z","iopub.status.idle":"2025-09-03T02:41:58.407737Z","shell.execute_reply.started":"2025-09-03T02:41:58.401375Z","shell.execute_reply":"2025-09-03T02:41:58.406371Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\n# vectorizer = CountVectorizer()\n\ntrain_sentences_tfidf = vectorizer.fit_transform(train_sentences)\ntest_sentences_tfidf = vectorizer.transform(test_sentences) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:43:14.253315Z","iopub.execute_input":"2025-09-03T02:43:14.253681Z","iopub.status.idle":"2025-09-03T02:43:15.739696Z","shell.execute_reply.started":"2025-09-03T02:43:14.253659Z","shell.execute_reply":"2025-09-03T02:43:15.737973Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.3.1 RandomOverSampler ","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn==1.3.0 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:40:51.629985Z","iopub.execute_input":"2025-09-03T02:40:51.630465Z","iopub.status.idle":"2025-09-03T02:40:55.911237Z","shell.execute_reply.started":"2025-09-03T02:40:51.630433Z","shell.execute_reply":"2025-09-03T02:40:55.909570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:40:59.311958Z","iopub.execute_input":"2025-09-03T02:40:59.312386Z","iopub.status.idle":"2025-09-03T02:40:59.592220Z","shell.execute_reply.started":"2025-09-03T02:40:59.312353Z","shell.execute_reply":"2025-09-03T02:40:59.591240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:41:00.726391Z","iopub.execute_input":"2025-09-03T02:41:00.727227Z","iopub.status.idle":"2025-09-03T02:41:00.733350Z","shell.execute_reply.started":"2025-09-03T02:41:00.727195Z","shell.execute_reply":"2025-09-03T02:41:00.731968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ros = RandomOverSampler(random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:41:02.209341Z","iopub.execute_input":"2025-09-03T02:41:02.209688Z","iopub.status.idle":"2025-09-03T02:41:02.214387Z","shell.execute_reply.started":"2025-09-03T02:41:02.209665Z","shell.execute_reply":"2025-09-03T02:41:02.213308Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_sentences_tfidf, train_labels = ros.fit_resample(train_sentences_tfidf, train_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:41:03.391008Z","iopub.execute_input":"2025-09-03T02:41:03.391471Z","iopub.status.idle":"2025-09-03T02:41:03.448475Z","shell.execute_reply.started":"2025-09-03T02:41:03.391443Z","shell.execute_reply":"2025-09-03T02:41:03.447439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Counter(train_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:41:04.741959Z","iopub.execute_input":"2025-09-03T02:41:04.742341Z","iopub.status.idle":"2025-09-03T02:41:04.765579Z","shell.execute_reply.started":"2025-09-03T02:41:04.742313Z","shell.execute_reply":"2025-09-03T02:41:04.764369Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.3.2 SMOTE ","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE, ADASYN ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:41:38.924568Z","iopub.execute_input":"2025-09-03T02:41:38.925202Z","iopub.status.idle":"2025-09-03T02:41:38.930528Z","shell.execute_reply.started":"2025-09-03T02:41:38.925166Z","shell.execute_reply":"2025-09-03T02:41:38.929167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_labels.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:43:22.841207Z","iopub.execute_input":"2025-09-03T02:43:22.841586Z","iopub.status.idle":"2025-09-03T02:43:22.849575Z","shell.execute_reply.started":"2025-09-03T02:43:22.841561Z","shell.execute_reply":"2025-09-03T02:43:22.848669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"smote = SMOTE(sampling_strategy='not majority') \ntrain_sentences_tfidf, train_labels = smote.fit_resample(train_sentences_tfidf, train_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:42:11.627571Z","iopub.execute_input":"2025-09-03T02:42:11.628007Z","iopub.status.idle":"2025-09-03T02:42:30.013177Z","shell.execute_reply.started":"2025-09-03T02:42:11.627975Z","shell.execute_reply":"2025-09-03T02:42:30.011966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"adasyn = ADASYN(sampling_strategy='not majority') \ntrain_sentences_tfidf, train_labels = adasyn.fit_resample(train_sentences_tfidf, train_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:43:26.003790Z","iopub.execute_input":"2025-09-03T02:43:26.005181Z","iopub.status.idle":"2025-09-03T02:46:07.731821Z","shell.execute_reply.started":"2025-09-03T02:43:26.005127Z","shell.execute_reply":"2025-09-03T02:46:07.730586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Counter(train_labels) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:46:14.956969Z","iopub.execute_input":"2025-09-03T02:46:14.957345Z","iopub.status.idle":"2025-09-03T02:46:14.975656Z","shell.execute_reply.started":"2025-09-03T02:46:14.957321Z","shell.execute_reply":"2025-09-03T02:46:14.974767Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Extract aspects ","metadata":{}},{"cell_type":"code","source":"seed_aspects = {\n    'vận_chuyển': ['giao hàng', 'tiki giao', 'nhận hàng'],\n    'đóng_gói': ['đóng gói', 'bao_bì'],\n    'sản_phẩm': ['cuốn sách', 'với giá', 'chất_lượng', 'sản_phẩm'] \n}\n\ndef extract_aspects(text, seed_aspects, vocab):\n    \"\"\"\n    Trả về list các tuple: (aspect_key, aspect_phrase, start_idx, end_idx)\n    start/end là index token trong tokenized sentence (inclusive).\n    \"\"\"\n    tokenized = vocab.tokenize_corpus([text])[0]  # assumes this returns list of tokens\n    t_low = [t.lower() for t in tokenized]\n    found = []\n    for asp_key, kws in seed_aspects.items():\n        for kw in kws:\n            kw_tokens = kw.lower().split()\n            L = len(kw_tokens)\n            if L == 0:\n                continue\n            for i in range(len(t_low) - L + 1):\n                if t_low[i:i+L] == kw_tokens:\n                    phrase = \" \".join(tokenized[i:i+L])\n                    found.append((asp_key, phrase, i, i+L-1))\n                    # break to avoid duplicate matches for same kw in same sentence\n                    break\n    return tokenized, found\n\ndef get_context_string(tokens, start, end, window=3):\n    left = max(0, start - window)\n    right = min(len(tokens)-1, end + window)\n    return \" \".join(tokens[left:right+1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. ML Model","metadata":{"id":"rd_WHu8v4Khn"}},{"cell_type":"markdown","source":"## 3.1 Multinomial Naive Bayes","metadata":{"id":"PkTBTlCX3BVW"}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","metadata":{"id":"Son705hwMCiM","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:41:14.125720Z","iopub.execute_input":"2025-09-03T02:41:14.126128Z","iopub.status.idle":"2025-09-03T02:41:14.136882Z","shell.execute_reply.started":"2025-09-03T02:41:14.126100Z","shell.execute_reply":"2025-09-03T02:41:14.135003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nb = MultinomialNB()\nnb.fit(train_sentences_tfidf, train_labels)","metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1746180731487,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"KSIB1HwdNlgX","outputId":"5475d948-2f88-42d1-dfef-af5bd5614bb5","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:46:26.104754Z","iopub.execute_input":"2025-09-03T02:46:26.105134Z","iopub.status.idle":"2025-09-03T02:46:26.154178Z","shell.execute_reply.started":"2025-09-03T02:46:26.105105Z","shell.execute_reply":"2025-09-03T02:46:26.153189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = nb.predict(test_sentences_tfidf)","metadata":{"id":"wBL3a8piNmYl","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:46:29.131243Z","iopub.execute_input":"2025-09-03T02:46:29.131576Z","iopub.status.idle":"2025-09-03T02:46:29.140108Z","shell.execute_reply.started":"2025-09-03T02:46:29.131552Z","shell.execute_reply":"2025-09-03T02:46:29.139016Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Accuracy:\", accuracy_score(test_labels, pred))\nprint(\"Classification Report:\")\nprint(classification_report(test_labels, pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(test_labels, pred))","metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1746180734935,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"-ht0JEjoNqgK","outputId":"3d4445cd-f5c6-4f04-918f-bf9ffc0b85c3","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:46:31.294345Z","iopub.execute_input":"2025-09-03T02:46:31.294869Z","iopub.status.idle":"2025-09-03T02:46:31.337866Z","shell.execute_reply.started":"2025-09-03T02:46:31.294825Z","shell.execute_reply":"2025-09-03T02:46:31.336485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label2sen = {0: \"Tiêu cực\", 1: \"Bình thường\", 2: \"Tích cực\"} ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Chạy Naive Bayes (gõ 'thoát' để dừng).\")\nwhile True:\n    input_text = input(\"Nhập câu cần kiểm tra: \").strip()\n    if input_text.lower() == \"thoát\":\n        print(\"Chúc một ngày tốt lành !\")\n        break\n\n    # tokenization + aspect extraction\n    tokenized, aspects = extract_aspects(clean_text(input_text), seed_aspects, vocab)\n\n    if len(aspects) == 0:\n        # fallback: toàn câu\n        vec = vectorizer.transform([clean_text(input_text)])\n        pred = model.predict(vec)[0]\n        print(\"Không tìm thấy aspect. Dự đoán cảm xúc toàn câu:\", label2sen[pred], \"\\n\")\n    else:\n        print(f\"Tìm thấy {len(aspects)} aspect:\")\n        for asp_key, asp_phrase, s, e in aspects:\n            context = get_context_string(tokenized, s, e, window=3)\n            vec = vectorizer.transform([context])\n            pred = model.predict(vec)[0]\n            print(f\" - Aspect '{asp_key}' (\\\"{asp_phrase}\\\") => {label2sen[pred]} (context: {context})\")\n        print()","metadata":{"executionInfo":{"elapsed":76177,"status":"ok","timestamp":1746174096531,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"e_e0rRMPULmq","outputId":"ecf8cbaa-26d3-491d-a6bc-cc3c681b63fc","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2 Random Forest ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:46:47.766401Z","iopub.execute_input":"2025-09-03T02:46:47.766758Z","iopub.status.idle":"2025-09-03T02:46:47.772862Z","shell.execute_reply.started":"2025-09-03T02:46:47.766734Z","shell.execute_reply":"2025-09-03T02:46:47.771523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf = RandomForestClassifier(max_depth=200, random_state=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:58:19.991462Z","iopub.execute_input":"2025-09-03T02:58:19.992657Z","iopub.status.idle":"2025-09-03T02:58:19.998187Z","shell.execute_reply.started":"2025-09-03T02:58:19.992574Z","shell.execute_reply":"2025-09-03T02:58:19.996836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf.fit(train_sentences_tfidf, train_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T02:58:21.391209Z","iopub.execute_input":"2025-09-03T02:58:21.391580Z","iopub.status.idle":"2025-09-03T03:02:49.533781Z","shell.execute_reply.started":"2025-09-03T02:58:21.391555Z","shell.execute_reply":"2025-09-03T03:02:49.532695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = clf.predict(test_sentences_tfidf) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:02:53.692438Z","iopub.execute_input":"2025-09-03T03:02:53.693742Z","iopub.status.idle":"2025-09-03T03:02:54.304843Z","shell.execute_reply.started":"2025-09-03T03:02:53.693692Z","shell.execute_reply":"2025-09-03T03:02:54.303143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Accuracy:\", accuracy_score(test_labels, pred))\nprint(\"Classification Report:\")\nprint(classification_report(test_labels, pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(test_labels, pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:02:57.170323Z","iopub.execute_input":"2025-09-03T03:02:57.170677Z","iopub.status.idle":"2025-09-03T03:02:57.202741Z","shell.execute_reply.started":"2025-09-03T03:02:57.170653Z","shell.execute_reply":"2025-09-03T03:02:57.201537Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. DL Model","metadata":{"id":"y4WZDW5wu9y2"}},{"cell_type":"markdown","source":"## 4.1 Word Embedding","metadata":{"id":"-uvILOwq_SbJ"}},{"cell_type":"code","source":"!pip install torch==2.2.0 ","metadata":{"executionInfo":{"elapsed":176883,"status":"ok","timestamp":1746194015784,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"NRwtkFQ_BMNt","outputId":"74c332cc-5ead-45a3-8e0f-cd3723c0f59e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchtext==0.17.0 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch \nimport torchtext.vocab as vocab","metadata":{"executionInfo":{"elapsed":4776,"status":"ok","timestamp":1746194050798,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"KlSyq9yz_ZLe","outputId":"3e4fce0d-2897-4f0b-ad0b-cf101ad85ba1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_path = '/kaggle/input/vietnamese-comment/vi_word2vec.txt'\noutput_path = '/kaggle/working/vi_word2vec_reduced.txt' \nmax_lines = 100000  # Số dòng bạn muốn giữ lại ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(input_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', encoding='utf-8') as outfile:\n    for i, line in enumerate(infile):\n        if i > max_lines:\n            break\n        outfile.write(line) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"word_embedding = vocab.Vectors(name = '/kaggle/working/vi_word2vec_reduced.txt', unk_init = torch.Tensor.normal_)\nword_embedding.vectors.shape","metadata":{"executionInfo":{"elapsed":103600,"status":"ok","timestamp":1746194158170,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"XNwfsCmxBk3K","outputId":"2d0c240f-d4d4-48c2-ffd9-c1706a04a6c5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_vector(embeddings, word):\n    assert word in embeddings.stoi, f'*{word}* is not in the vocab!'\n    return embeddings.vectors[embeddings.stoi[word]]\n\ndef closest_words(embeddings, vector, n=10):\n    distances = [(word, torch.dist(vector, get_vector(embeddings, word)).item())\n                 for word in embeddings.itos]\n\n    return sorted(distances, key = lambda w: w[1])[:n]","metadata":{"executionInfo":{"elapsed":15471,"status":"ok","timestamp":1746194194823,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"Ug_yYagDIxD3","outputId":"e1cf4730-d8c1-4c4a-e0a4-6824f3ce1eee","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"word_vector = get_vector(word_embedding, \"Lạc_Long_Quân\")\n\nclosest_words(word_embedding, word_vector, n=20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2 Vocabulary Class","metadata":{"id":"kPhuKPoCKP4Y"}},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"TUzIsdjUI8Yv","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Vocabulary:\n    def __init__(self):\n        self.word2id = dict()\n        self.word2id['<pad>'] = 0   # Pad Token\n        self.word2id['<unk>'] = 1   # Unknown Token\n        self.unk_id = self.word2id['<unk>']\n        self.id2word = {v: k for k, v in self.word2id.items()}\n\n    def __getitem__(self, word):\n        return self.word2id.get(word, self.unk_id)\n\n    def __contains__(self, word):\n        return word in self.word2id\n\n    def __len__(self):\n        return len(self.word2id)\n\n    def id2word(self, word_index):\n        return self.id2word[word_index]\n\n    def add(self, word):\n        if word not in self:\n            word_index = self.word2id[word] = len(self.word2id)\n            self.id2word[word_index] = word\n            return word_index\n        else:\n            return self[word]\n\n    @staticmethod\n    def tokenize_corpus(corpus):\n        print(\"Tokenize the corpus...\")\n        tokenized_corpus = list()\n        for document in tqdm(corpus):\n            tokenized_document = [word.replace(\" \", \"_\") for word in word_tokenize(document)]\n            tokenized_corpus.append(tokenized_document)\n\n        return tokenized_corpus\n\n    def corpus_to_tensor(self, corpus, is_tokenized=False):\n        if is_tokenized:\n            tokenized_corpus = corpus\n        else:\n            tokenized_corpus = self.tokenize_corpus(corpus)\n        indicies_corpus = list()\n        for document in tqdm(tokenized_corpus):\n            indicies_document = torch.tensor(list(map(lambda word: self[word], document)),\n                                             dtype=torch.int64)\n            indicies_corpus.append(indicies_document)\n\n        return indicies_corpus\n\n    def tensor_to_corpus(self, tensor):\n        corpus = list()\n        for indicies in tqdm(tensor):\n            document = list(map(lambda index: self.id2word[index.item()], indicies))\n            corpus.append(document)\n\n        return corpus\n\n    # def add_words_from_corpus(self, corpus, is_tokenized=False):\n    #     print(\"Add words from the corpus...\")\n    #     if is_tokenized:\n    #         tokenized_corpus = corpus\n    #     else:\n    #         tokenized_corpus = self.tokenize_corpus(corpus)\n    #     word_freq = Counter(chain(*tokenized_corpus))\n    #     non_singletons = [w for w in word_freq if word_freq[w] > 1]\n    #     print(f\"Number of words in the corpus: {len(word_freq)}\")\n    #     print(f\"Number of words with frequency > 1: {len(non_singletons)}\")\n    #     for word in non_singletons:\n    #         self.add(word)","metadata":{"id":"y0OKmH59JRNR","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corpus_sample = [\"Đẹp lắm mn ơi k ngờ fahasa bán alb thơ này của Lana lun, bh khó mua lắm\",\n                 \"Shop giao hàng nhanh, đóng gói hàng cẩn thận. Mặc dù sách có bé hơn mình nghĩ nhưng shop rất chu đáo. Vì mình mua gần tết nên có đc tặng thêm cả lì xì nữa. Rất đáng tiền. Mn mua ủng hộ shop nhé.\",\n                 \"lần đầu mua nhưng ok lắm luôn sắp tết nên đc tặng tập lì xì sách nhỏ nhưng bọc hộp đầy đủ đặc biệt tặng cả voucher cho lần sau chỉ có cái sách được bọc bằng màng thực phẩm\"]\n\nVocabulary.tokenize_corpus(corpus_sample)","metadata":{"executionInfo":{"elapsed":753,"status":"ok","timestamp":1746194235139,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"qPuoNxT8Jssh","outputId":"60fa012f-5e6c-4213-fa79-da45b15fd327","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vocab = Vocabulary()\n\n# create vocabulary from pretrained word2vec\nwords_list = list(word_embedding.stoi.keys())\nfor word in words_list:\n    vocab.add(word)\n\n# test the vocabulary\ntensor = vocab.corpus_to_tensor(corpus_sample)\ncorpus = vocab.tensor_to_corpus(tensor)\n\" \".join(corpus[0])","metadata":{"executionInfo":{"elapsed":1427,"status":"ok","timestamp":1746194239758,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"CN5owFxXJ0ad","outputId":"588e75fb-406f-4322-dea2-c730afa3b7d3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.3 CommentDataset Class","metadata":{"id":"AUU-I4_4KgNQ"}},{"cell_type":"code","source":"from scipy.linalg.special_matrices import dft\nfrom torch.utils.data import Dataset","metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1746194243323,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"ANHI2NEuKB7U","outputId":"7240a3da-1e92-40be-9c1e-ad707d4baa3a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CommentDataset(Dataset):\n\n    def __init__(self, vocab, df, tokenized_fpath=None):\n        self.vocab = vocab\n        self.pad_idx = vocab[\"<pad>\"]\n        df = df\n        self.sentiments_list = list(df.label)\n        self.reviews_list = list(df.text)\n\n        sentiments_type = list(set(self.sentiments_list))\n        sentiments_type.sort()\n\n        self.sentiment2id = {sentiment: i for i, sentiment in enumerate(sentiments_type)}\n\n        if tokenized_fpath:\n            self.tokenized_reviews = torch.load(tokenized_fpath)\n        else:\n            self.tokenized_reviews = self.vocab.tokenize_corpus(self.reviews_list)\n\n        self.tensor_data = self.vocab.corpus_to_tensor(self.tokenized_reviews, is_tokenized=True)\n        self.tensor_label = torch.tensor([self.sentiment2id[sentiment] for sentiment in self.sentiments_list],\n                                         dtype=torch.float64)\n\n        self.tensor_data, self.tensor_label = zip(*[(data, label) for data, label in zip(self.tensor_data, self.tensor_label) if len(data) > 0])\n        self.tensor_data = list(self.tensor_data)\n        self.tensor_label = torch.tensor(self.tensor_label, dtype=torch.float64) # Convert back to tensor\n\n    def __len__(self):\n        return len(self.tensor_data)\n\n    def __getitem__(self, idx):\n        return self.tensor_data[idx], self.tensor_label[idx]\n\n    def collate_fn(self, examples):\n        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n\n        reviews = [e[0] for e in examples]\n        reviews = torch.nn.utils.rnn.pad_sequence(reviews,\n                                                  batch_first=False,\n                                                  padding_value=self.pad_idx)\n        reviews_lengths = torch.tensor([len(e[0]) for e in examples])\n        sentiments = torch.tensor([e[1] for e in examples])\n\n        return {\"reviews\": (reviews, reviews_lengths), \"sentiments\": sentiments}","metadata":{"id":"kuT630Y0KvBm","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.utils import resample ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.DataFrame({\n    'text': train_sentences,\n    'label': train_labels\n})\n\ndf_pos = df_train[df_train.label == 2]   # positive\ndf_neg = df_train[df_train.label == 0]   # negative\ndf_neu = df_train[df_train.label == 1]   # neutral\n\nmax_n = df_train.label.value_counts().max()\n\ndf_neg_up = resample(df_neg,\n                     replace=True,\n                     n_samples=max_n,\n                     random_state=42)\ndf_neu_up = resample(df_neu,\n                     replace=True,\n                     n_samples=max_n,\n                     random_state=42)\n\ndf_pos_up = df_pos\n\ntrain_balanced = pd.concat([df_pos_up, df_neg_up, df_neu_up])\ntrain_balanced = train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_df = train_balanced.sample(frac=0.2, random_state=42).reset_index()\ntrain_df = train_balanced.drop(valid_df.index).reset_index()\ntest_df = pd.DataFrame({\n    'text': test_sentences,\n    'label': test_labels\n}).reset_index()","metadata":{"id":"ceP8RzYJLSbF","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_df['label'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" valid_df.drop(columns=['index'], inplace=True)\n train_df.drop(columns=['index'], inplace=True)\n test_df.drop(columns=['index'], inplace=True)","metadata":{"id":"yXs1JIFeL5V9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = CommentDataset(vocab, train_df)\nvalid_dataset = CommentDataset(vocab, valid_df)\ntest_dataset = CommentDataset(vocab, test_df)","metadata":{"executionInfo":{"elapsed":136089,"status":"ok","timestamp":1746194391233,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"bm8J8t-XMGUW","outputId":"6317c80d-6e3d-4d86-c908-544bb9f8b60b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.4 Create DataLoader ","metadata":{"id":"0dJyD-NkN6qR"}},{"cell_type":"code","source":"from torch.utils.data import DataLoader","metadata":{"id":"ok2-GZhwNvWs","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 32\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, collate_fn=train_dataset.collate_fn)\nvalid_dataloader = DataLoader(valid_dataset, shuffle=True, batch_size=batch_size, collate_fn=valid_dataset.collate_fn)\ntest_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size, collate_fn=test_dataset.collate_fn)","metadata":{"id":"Ry9tY3fVOFR9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.5 RNN Model","metadata":{"id":"DvsY8fMg3KUY"}},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"id":"sDEYcDrgOHe5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers,\n                 bidirectional, dropout, pad_idx, n_classes):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n        self.rnn = nn.LSTM(\n            embedding_dim,\n            hidden_dim,\n            num_layers=n_layers,\n            bidirectional=bidirectional,\n            dropout=dropout if n_layers > 1 else 0\n        )\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), n_classes)\n\n    def forward(self, text, text_lengths):\n        embedded = self.dropout(self.embedding(text))\n        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n            embedded, text_lengths.to('cpu'), enforce_sorted=False\n        )\n        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n        if self.rnn.bidirectional:\n            hidden = self.dropout(torch.cat((hidden[-2], hidden[-1]), dim=1))\n        else:\n            hidden = self.dropout(hidden[-1])\n        return self.fc(hidden)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_dim = word_embedding.vectors.shape[0] \nembedding_dim = 100\nhidden_dim = 8  \nn_layers = 2\nbidirectional = False \ndropout = 0.3 \npad_idx = vocab[\"<pad>\"]\nunk_idx = vocab[\"<unk>\"]\nn_classes = 3  # positive, neutral, negative\n\nmodel = RNN(input_dim, embedding_dim, hidden_dim, n_layers, bidirectional, dropout, pad_idx, n_classes)","metadata":{"id":"4_4gdqbc77CI","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.embedding.weight.data.copy_(word_embedding.vectors)\nmodel.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\nmodel.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)","metadata":{"id":"syPlzxAlPq2f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"executionInfo":{"elapsed":40,"status":"ok","timestamp":1746194406406,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"dI2rLTSjP2Wf","outputId":"97310f26-c1da-48f7-b70f-385aca59b885","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.6 Train the model","metadata":{"id":"-MF9RoIfP9ag"}},{"cell_type":"code","source":"import torch.optim as optim\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score","metadata":{"id":"tPTimkkcQFt0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss().to(device) \n\nmodel = model.to(device)","metadata":{"id":"sSRqCavQP6aP","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metrics_1(preds, labels):\n    acc = accuracy_score(labels, preds)\n    return acc ","metadata":{"id":"ur6s3FBBQIb4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metrics_2(preds, labels):\n    acc = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        labels, preds, average='weighted', zero_division=0\n    )\n    return acc, precision, recall, f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(model, dataloader, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    all_preds, all_labels = [], []\n\n    for batch in dataloader:\n        optimizer.zero_grad()\n        reviews, lengths = batch['reviews']\n        reviews, lengths = reviews.to(device), lengths.to(device)\n        logits = model(reviews, lengths)\n        labels = batch['sentiments'].long().squeeze(-1).to(device)\n\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n\n        preds = logits.argmax(dim=1).cpu().tolist()\n        all_preds.extend(preds)\n        all_labels.extend(labels.cpu().tolist())\n\n    acc = compute_metrics_1(all_preds, all_labels)\n    return epoch_loss / len(dataloader), acc ","metadata":{"id":"TSfvzJqKQM47","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_1(model, dataloader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            reviews, lengths = batch['reviews']\n            reviews, lengths = reviews.to(device), lengths.to(device)\n            logits = model(reviews, lengths)\n            labels = batch['sentiments'].long().squeeze(-1).to(device)\n\n            loss = criterion(logits, labels)\n            epoch_loss += loss.item()\n\n            preds = logits.argmax(dim=1).cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().tolist())\n\n    acc = compute_metrics_1(all_preds, all_labels)\n    return epoch_loss / len(dataloader), acc","metadata":{"id":"7GOYp5OIQP6j","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_2(model, dataloader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            reviews, lengths = batch['reviews']\n            reviews, lengths = reviews.to(device), lengths.to(device)\n            logits = model(reviews, lengths)\n            labels = batch['sentiments'].long().squeeze(-1).to(device)\n\n            loss = criterion(logits, labels)\n            epoch_loss += loss.item()\n\n            preds = logits.argmax(dim=1).cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().tolist())\n\n    acc, precision, recall, f1 = compute_metrics_2(all_preds, all_labels)\n    return epoch_loss / len(dataloader), acc, precision, recall, f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time","metadata":{"id":"3IbqwPJuQZ2d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"id":"h6CMYJsaQSpW","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_epochs = 5\n\nbest_valid_loss = float(\"inf\")\n\nfor epoch in range(n_epochs):\n    start_time = time.time()\n\n    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, device)\n    valid_loss, valid_acc = evaluate_1(model, valid_dataloader, criterion, device)\n\n    end_time = time.time()\n\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'model.pt')\n\n    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n    print(f\"  Train - loss: {train_loss:.3f}| acc: {train_acc:.2f}\")\n    print(f\"  Valid - loss: {valid_loss:.3f}| acc: {valid_acc:.2f}\")","metadata":{"id":"zASLf1b3QcQi","outputId":"9d7d9954-7661-4a67-b0ac-32acfa4f6104","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.7 Test the model ","metadata":{}},{"cell_type":"code","source":"test_loss, test_acc, test_prec, test_rec, test_f1 = evaluate_2(model, test_dataloader, criterion, device)\n\nprint(f\"Test - loss: {test_loss:.3f}| acc: {test_acc:.2f}| prec: {test_prec:.2f}| rec: {test_rec:.2f}| f1: {test_f1:.2f}\")","metadata":{"id":"O1H6T20mUDgD","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_sentiment(model, sentence, vocab, device, label_mapping=None):\n    model.eval()\n\n    # Convert sentence to tensor of token indices\n    corpus = [sentence]\n    tensor = vocab.corpus_to_tensor(corpus)[0].to(device)        # [seq_len]\n    tensor = tensor.unsqueeze(1)                                 # [seq_len, 1]\n    length_tensor = torch.LongTensor([tensor.size(0)]).to(device)\n\n    # Forward pass\n    with torch.no_grad():\n        logits = model(tensor, length_tensor).squeeze(0)         # [n_classes]\n        probs = F.softmax(logits, dim=-1)                       # [n_classes]\n\n    # Predicted class index and optional label name\n    pred_idx = probs.argmax().item()\n    pred_label = label_mapping[pred_idx] if label_mapping is not None else str(pred_idx)\n\n    # Return index, label, and full probability distribution\n    return pred_label, probs.cpu().tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_map = {0: 'tiêu cực', 1: 'bình thường', 2: 'tích cực'}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Chạy BiLSTM (gõ 'thoát' để dừng).\")\nwhile True:\n    input_text = input(\"Nhập câu cần kiểm tra: \").strip()\n    if input_text.lower() == \"thoát\":\n        print(\"Chúc một ngày tốt lành!\")\n        break\n\n    tokenized, aspects = extract_aspects(clean_text(input_text), seed_aspects, vocab)\n\n    if len(aspects) == 0:\n        # fallback: toàn câu\n        sent, probs = predict_sentiment(model=model,\n                                        sentence=clean_text(input_text),\n                                        vocab=vocab,\n                                        device=device,\n                                        label_mapping=label_map)\n        print(f\"Dự đoán cảm xúc toàn câu: {sent}\\n\")\n    else:\n        print(f\"Tìm thấy {len(aspects)} aspect:\")\n        for asp_key, asp_phrase, s, e in aspects:\n            context_tokens = tokenized  # we already have tokens; build small window\n            context = get_context_string(context_tokens, s, e, window=3)\n            sent, probs = predict_sentiment(model=model,\n                                            sentence=context,\n                                            vocab=vocab,\n                                            device=device,\n                                            label_mapping=label_map)\n            print(f\" - Aspect '{asp_key}' (\\\"{asp_phrase}\\\") → {sent} (context: {context})\")\n        print()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}