{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"authorship_tag":"ABX9TyMKBNv0DgMROlxH5KUikvBG"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11939197,"sourceType":"datasetVersion","datasetId":7314670}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Preparing the Dataset","metadata":{"id":"xAVF_OkQ4Bie"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:01:48.350038Z","iopub.execute_input":"2025-08-30T08:01:48.350286Z","iopub.status.idle":"2025-08-30T08:01:48.356195Z","shell.execute_reply.started":"2025-08-30T08:01:48.350260Z","shell.execute_reply":"2025-08-30T08:01:48.355380Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/vietnamese-comment/comments.csv\n/kaggle/input/vietnamese-comment/vi_word2vec.txt\n/kaggle/input/vietnamese-comment/extra.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport re ","metadata":{"id":"C_70PqesOxnp","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:01:48.357016Z","iopub.execute_input":"2025-08-30T08:01:48.357279Z","iopub.status.idle":"2025-08-30T08:01:48.383921Z","shell.execute_reply.started":"2025-08-30T08:01:48.357255Z","shell.execute_reply":"2025-08-30T08:01:48.383193Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data_path_1 = '/kaggle/input/vietnamese-comment/comments.csv'\ndata_path_2 = '/kaggle/input/vietnamese-comment/extra.csv' ","metadata":{"executionInfo":{"elapsed":17824,"status":"ok","timestamp":1746193805847,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"vDsAVM7jfp-F","outputId":"7fa7ea5d-243d-42dd-ba4d-0aa1065f2334","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:01:50.663294Z","iopub.execute_input":"2025-08-30T08:01:50.663830Z","iopub.status.idle":"2025-08-30T08:01:50.667557Z","shell.execute_reply.started":"2025-08-30T08:01:50.663807Z","shell.execute_reply":"2025-08-30T08:01:50.666830Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_1 = pd.read_csv(data_path_1)\ndata_1.head()","metadata":{"executionInfo":{"elapsed":2089,"status":"ok","timestamp":1746193810496,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"7YUIE0d3P4JD","outputId":"063eac9b-2064-4ead-9129-5f9eeb8c0039","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:01:53.066857Z","iopub.execute_input":"2025-08-30T08:01:53.067657Z","iopub.status.idle":"2025-08-30T08:01:53.605265Z","shell.execute_reply.started":"2025-08-30T08:01:53.067630Z","shell.execute_reply":"2025-08-30T08:01:53.604656Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                title                                            content  \\\n0     Cực kì hài lòng  Được hẹn giao hàng thứ 4 mà thứ 2 đã có sách t...   \n1  Rất không hài lòng  Hàng giả.  Giấy sách quá tệ. Chữ in ko rõ ràng...   \n2     Cực kì hài lòng  Sách đẹp, chất lượng giấy tuyệt vời, khổ to, n...   \n3     Cực kì hài lòng  Giao hàng nhanh, đóng gói cẩn thận. Có bóng kí...   \n4     Cực kì hài lòng        Giao nhanh và đóng gói cẩn thận. Thank shop   \n\n   rating  \n0       5  \n1       1  \n2       5  \n3       5  \n4       5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>content</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cực kì hài lòng</td>\n      <td>Được hẹn giao hàng thứ 4 mà thứ 2 đã có sách t...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rất không hài lòng</td>\n      <td>Hàng giả.  Giấy sách quá tệ. Chữ in ko rõ ràng...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cực kì hài lòng</td>\n      <td>Sách đẹp, chất lượng giấy tuyệt vời, khổ to, n...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Cực kì hài lòng</td>\n      <td>Giao hàng nhanh, đóng gói cẩn thận. Có bóng kí...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cực kì hài lòng</td>\n      <td>Giao nhanh và đóng gói cẩn thận. Thank shop</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"len(data_1) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_2 = pd.read_csv(data_path_2)\ndata_2.head()","metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1746193812178,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"uzkSZ0Shdzt6","outputId":"d9a7f01d-8250-4fdb-8119-f638504e4ddc","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(data_2) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data_1 = data_1.drop(columns=['title'])\n# data = pd.concat([data_1, data_2])\n\ndata = data_1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:01:57.921425Z","iopub.execute_input":"2025-08-30T08:01:57.921889Z","iopub.status.idle":"2025-08-30T08:01:57.925325Z","shell.execute_reply.started":"2025-08-30T08:01:57.921866Z","shell.execute_reply":"2025-08-30T08:01:57.924696Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data.head(10) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(data) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values = data.isnull().sum()\nprint(\"Dữ liệu bị thiếu:\\n\", missing_values)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"duplicates = data.duplicated(subset=[\"content\"]).sum()\nprint(\"Số câu trùng lặp:\", duplicates)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Data Preprocessing","metadata":{"id":"8ZYScp6ADQOX"}},{"cell_type":"markdown","source":"## 2.1 Data Cleaning","metadata":{"id":"LGaJuM4WD1eT"}},{"cell_type":"code","source":"# data = data.dropna(subset=[\"content\"])           # bỏ comment rỗng\ndata = data.dropna(subset=['title', 'content']) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:02:03.706406Z","iopub.execute_input":"2025-08-30T08:02:03.707127Z","iopub.status.idle":"2025-08-30T08:02:03.743083Z","shell.execute_reply.started":"2025-08-30T08:02:03.707092Z","shell.execute_reply":"2025-08-30T08:02:03.742303Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"len(data)","metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1746193815494,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"6gcND-Kbd5nN","outputId":"d98cee72-c031-424a-eb30-43168952e83b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import unicodedata","metadata":{"id":"mdpDYHzWVnK_","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:02:07.431010Z","iopub.execute_input":"2025-08-30T08:02:07.431295Z","iopub.status.idle":"2025-08-30T08:02:07.434960Z","shell.execute_reply.started":"2025-08-30T08:02:07.431263Z","shell.execute_reply":"2025-08-30T08:02:07.434272Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Dictionary for common Vietnamese slang/abbreviations\nabbreviations = {\n    \"ko\": \"không\",\n    \"sp\": \"sản phẩm\",\n    \"k\": \"không\",\n    \"m\": \"mình\",\n    \"đc\": \"được\",\n    \"dc\": \"được\",\n    \"h\": \"giờ\",\n    \"trloi\": \"trả lời\",\n    \"cg\": \"cũng\",\n    \"bt\": \"bình thường\",\n    \"dt\": \"điện thoại\",\n    \"mt\": \"máy tính\",\n    \"m.n\": \"mọi người\"\n    # add more slang mappings\n}\n\n# Regex patterns\nurl_pattern = r\"http\\S+|www\\S+\"  # URLs\nuser_pattern = r\"@\\w+\"  # usernames\nemoji_pattern = re.compile(\n    \"[\"  # start\n    \"\\U0001F600-\\U0001F64F\"  # emoticons\n    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n    \"\\U0001F1E0-\\U0001F1FF\"  # flags\n    \"]+\", flags=re.UNICODE)\nemoticon_pattern = r\"[:;=8][\\-o\\*']?[\\)\\]\\(\\[dDpP/:}\\{@\\|\\\\]\"  # emoticons\nrepeat_pattern = re.compile(r\"(.)\\1{2,}\")  # 3 or more repeats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:02:28.748805Z","iopub.execute_input":"2025-08-30T08:02:28.749321Z","iopub.status.idle":"2025-08-30T08:02:28.754368Z","shell.execute_reply.started":"2025-08-30T08:02:28.749298Z","shell.execute_reply":"2025-08-30T08:02:28.753708Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def clean_text(text: str) -> str:\n    # Unicode normalization\n    text = str(text)\n    text = unicodedata.normalize('NFC', text)  # Chuẩn hoá Unicode rõ ràng (căn bản)\n\n    # Lowercase\n    text = text.lower()\n\n    # Remove URLs and usernames\n    text = re.sub(url_pattern, '', text)\n    text = re.sub(user_pattern, '', text)\n\n    # Remove emojis and emoticons\n    text = emoji_pattern.sub(' ', text)\n    text = re.sub(emoticon_pattern, ' ', text)\n\n    # Expand common abbreviations\n    def expand(match):\n        word = match.group(0)\n        return abbreviations.get(word, word)\n\n    if abbreviations:\n        pattern = re.compile(r\"\\b(\" + \"|\".join(map(re.escape, abbreviations.keys())) + r\")\\b\")\n        text = pattern.sub(expand, text)\n\n    # Remove repeated characters (e.g., \"quaaa\" -> \"qua\" )\n    text = repeat_pattern.sub(r\"\\1\", text)\n\n    # Remove punctuation (keep Vietnamese letters & numbers)\n    text = re.sub(r\"[^\\w\\s\\u00C0-\\u024F]\", ' ', text)\n\n    # Remove extra whitespace\n    text = re.sub(r\"\\s+\", ' ', text).strip()\n\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:02:32.494056Z","iopub.execute_input":"2025-08-30T08:02:32.494685Z","iopub.status.idle":"2025-08-30T08:02:32.500225Z","shell.execute_reply.started":"2025-08-30T08:02:32.494662Z","shell.execute_reply":"2025-08-30T08:02:32.499585Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"sample = \"Tui thik qááá!!! 😊😊, thanks @ban http://example.com\"\nprint(clean_text(sample))  # Expected: \"tui thích qua cảm ơn\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:02:36.125088Z","iopub.execute_input":"2025-08-30T08:02:36.125830Z","iopub.status.idle":"2025-08-30T08:02:36.129942Z","shell.execute_reply.started":"2025-08-30T08:02:36.125805Z","shell.execute_reply":"2025-08-30T08:02:36.129163Z"}},"outputs":[{"name":"stdout","text":"tui thik qá thanks\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"data[\"text\"] = data[\"content\"].apply(clean_text)","metadata":{"id":"1hcGFVNdVqvk","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:02:38.085475Z","iopub.execute_input":"2025-08-30T08:02:38.086167Z","iopub.status.idle":"2025-08-30T08:02:41.437814Z","shell.execute_reply.started":"2025-08-30T08:02:38.086142Z","shell.execute_reply":"2025-08-30T08:02:41.437105Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_121/4067448078.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[\"text\"] = data[\"content\"].apply(clean_text)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"data.head()","metadata":{"executionInfo":{"elapsed":260,"status":"ok","timestamp":1746193819053,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"O2XJfW-dVtpQ","outputId":"55efdbe7-166a-4aec-c4b9-8e9fd1224ac0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = data.groupby('text', as_index=False)['rating'].mean()  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:02:46.599978Z","iopub.execute_input":"2025-08-30T08:02:46.600249Z","iopub.status.idle":"2025-08-30T08:02:46.730799Z","shell.execute_reply.started":"2025-08-30T08:02:46.600227Z","shell.execute_reply":"2025-08-30T08:02:46.730212Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"data['rating'] = np.floor(data['rating']).astype(int) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:02:49.478670Z","iopub.execute_input":"2025-08-30T08:02:49.479214Z","iopub.status.idle":"2025-08-30T08:02:49.484243Z","shell.execute_reply.started":"2025-08-30T08:02:49.479193Z","shell.execute_reply":"2025-08-30T08:02:49.483460Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"duplicates = data.duplicated(subset=[\"text\"]).sum()\nprint(\"Số câu trùng lặp sau xử lý:\", duplicates) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def sentiment(r):\n    if r >= 4: return \"tích cực\"\n    if r == 3: return \"bình thường\"\n    return \"tiêu cực\"\ndef label(r):\n    if r >= 4: return 2\n    if r == 3: return 1\n    return 0\ndata[\"sentiment\"] = data[\"rating\"].apply(sentiment)\ndata[\"label\"] = data[\"rating\"].apply(label)","metadata":{"id":"vX1efgvuebd6","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:02:52.426637Z","iopub.execute_input":"2025-08-30T08:02:52.427211Z","iopub.status.idle":"2025-08-30T08:02:52.451442Z","shell.execute_reply.started":"2025-08-30T08:02:52.427178Z","shell.execute_reply":"2025-08-30T08:02:52.450832Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"data.head()","metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1746193821607,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"5iVRzBnqeghM","outputId":"2398a97d-ce17-45c1-d429-250f9296dea6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2 Statistical Analysis","metadata":{"id":"tGRmgNK5D89Q"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"id":"gv976yWHWcaA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Số lượng mẫu:\", data.shape[0])","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1746193825497,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"VwBOfngAWf4D","outputId":"d4863a13-a29d-46ef-9ec5-776935629c8e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nsns.countplot(x=data[\"sentiment\"], palette=\"coolwarm\")\nplt.title(\"Phân phối nhãn cảm xúc\")\nplt.xlabel(\"Cảm xúc\")\nplt.ylabel(\"Số lượng mẫu\")\nplt.show()","metadata":{"executionInfo":{"elapsed":461,"status":"ok","timestamp":1746193827036,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"iJG9XwFVWlub","outputId":"47ce09af-04be-4643-df07-c2e9975570b1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values = data.isnull().sum()\nprint(\"Dữ liệu bị thiếu:\\n\", missing_values)","metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1746193828233,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"j3x1DPRXWpj8","outputId":"d3cf5b28-3c0e-4d11-8a1f-2a5251d9761e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_counts = data[\"sentiment\"].value_counts()\nprint(\"Số lượng mỗi nhãn:\\n\", label_counts)","metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1746193831015,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"gvWYi5LLXZSO","outputId":"ee01d7ee-aea6-4c5c-92c4-7382a5289079","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install underthesea ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:02:59.557286Z","iopub.execute_input":"2025-08-30T08:02:59.557576Z","iopub.status.idle":"2025-08-30T08:03:02.689815Z","shell.execute_reply.started":"2025-08-30T08:02:59.557554Z","shell.execute_reply":"2025-08-30T08:03:02.688828Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: underthesea in /usr/local/lib/python3.11/dist-packages (6.8.4)\nRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from underthesea) (8.1.8)\nRequirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.11/dist-packages (from underthesea) (0.9.11)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from underthesea) (3.9.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from underthesea) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from underthesea) (2.32.3)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.4.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.2.2)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from underthesea) (6.0.2)\nRequirement already satisfied: underthesea-core==1.0.4 in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.0.4)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->underthesea) (2024.11.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2025.1.31)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.15.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn->underthesea) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from underthesea import word_tokenize\nimport nltk\nimport wordcloud","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:06.388084Z","iopub.execute_input":"2025-08-30T08:03:06.388668Z","iopub.status.idle":"2025-08-30T08:03:11.936017Z","shell.execute_reply.started":"2025-08-30T08:03:06.388640Z","shell.execute_reply":"2025-08-30T08:03:11.935447Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"data['corpus'] = data['text'].map(lambda text: word_tokenize(text, format=\"text\")) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:12:34.848844Z","iopub.execute_input":"2025-08-30T08:12:34.849136Z","iopub.status.idle":"2025-08-30T08:13:44.142842Z","shell.execute_reply.started":"2025-08-30T08:12:34.849117Z","shell.execute_reply":"2025-08-30T08:13:44.142058Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"data.sample(10) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create bag of words\n# Flatten the list of lists into a single list of words\nall_words_flat = []\nfor tokens in data['corpus'].tolist():\n    if tokens and tokens != '':\n        all_words_flat.extend(tokens.split())\n\n# Create FreqDist from the flattened list\nall_words_dist = nltk.FreqDist(all_words_flat)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:13:44.862585Z","iopub.execute_input":"2025-08-30T08:13:44.862780Z","iopub.status.idle":"2025-08-30T08:13:45.539155Z","shell.execute_reply.started":"2025-08-30T08:13:44.862765Z","shell.execute_reply":"2025-08-30T08:13:45.538570Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Print the total number of words and the 15 most common words\nprint('Tổng số từ: {}'.format(len(all_words_dist)))\nprint('Từ xuất hiện nhiều: {}'.format(all_words_dist.most_common(15)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:13:45.540339Z","iopub.execute_input":"2025-08-30T08:13:45.540603Z","iopub.status.idle":"2025-08-30T08:13:45.550867Z","shell.execute_reply.started":"2025-08-30T08:13:45.540573Z","shell.execute_reply":"2025-08-30T08:13:45.550097Z"}},"outputs":[{"name":"stdout","text":"Tổng số từ: 40490\nTừ xuất hiện nhiều: [('không', 24313), ('sách', 22953), ('mình', 20073), ('hàng', 17416), ('và', 16640), ('có', 16532), ('rất', 16104), ('được', 14852), ('là', 14011), ('giao', 13207), ('thì', 12079), ('mua', 10990), ('nhưng', 10551), ('của', 10049), ('nên', 10011)]\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"corpus = \" \".join(all_words_flat)\nplt.figure(figsize=(12,8))\nword_cloud = wordcloud.WordCloud(max_words=100, background_color =\"black\", width=2000, height=1000, mode=\"RGB\").generate(corpus)\nplt.axis(\"off\")\nplt.imshow(word_cloud)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3 Oversampling","metadata":{"id":"_b-MYlkuEJoD"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"id":"L8qIy5ekB4I9","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:17.268366Z","iopub.execute_input":"2025-08-30T08:03:17.269257Z","iopub.status.idle":"2025-08-30T08:03:17.272364Z","shell.execute_reply.started":"2025-08-30T08:03:17.269232Z","shell.execute_reply":"2025-08-30T08:03:17.271761Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n    data['text'],\n    data['label'],\n    test_size=0.2,\n    stratify=data['label'],\n    random_state=42\n)","metadata":{"id":"eeAd3GCb-GkT","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:19.317818Z","iopub.execute_input":"2025-08-30T08:03:19.318085Z","iopub.status.idle":"2025-08-30T08:03:19.340946Z","shell.execute_reply.started":"2025-08-30T08:03:19.318063Z","shell.execute_reply":"2025-08-30T08:03:19.340032Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from sklearn.utils import resample","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:22.027341Z","iopub.execute_input":"2025-08-30T08:03:22.027654Z","iopub.status.idle":"2025-08-30T08:03:22.031314Z","shell.execute_reply.started":"2025-08-30T08:03:22.027631Z","shell.execute_reply":"2025-08-30T08:03:22.030573Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df_train = pd.DataFrame({\n    'text': train_sentences,\n    'label': train_labels\n})\n\ndf_pos = df_train[df_train.label == 2]   # positive\ndf_neg = df_train[df_train.label == 0]   # negative\ndf_neu = df_train[df_train.label == 1]   # neutral\n\nmax_n = df_train.label.value_counts().max()\n\ndf_neg_up = resample(df_neg,\n                     replace=True,\n                     n_samples=max_n,\n                     random_state=42)\ndf_neu_up = resample(df_neu,\n                     replace=True,\n                     n_samples=max_n,\n                     random_state=42)\n\ndf_pos_up = df_pos\n\ntrain_balanced = pd.concat([df_pos_up, df_neg_up, df_neu_up])\ntrain_balanced = train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n\ntrain_sentences = train_balanced['text']\ntrain_labels    = train_balanced['label']","metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1746193834633,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"zQQTBvoXAIH0","outputId":"75785bc9-a527-4422-dc0b-0c1145c1103c","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:24.622734Z","iopub.execute_input":"2025-08-30T08:03:24.623003Z","iopub.status.idle":"2025-08-30T08:03:24.654581Z","shell.execute_reply.started":"2025-08-30T08:03:24.622984Z","shell.execute_reply":"2025-08-30T08:03:24.653961Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"print(train_balanced['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:28.569099Z","iopub.execute_input":"2025-08-30T08:03:28.569394Z","iopub.status.idle":"2025-08-30T08:03:28.575700Z","shell.execute_reply.started":"2025-08-30T08:03:28.569371Z","shell.execute_reply":"2025-08-30T08:03:28.574889Z"}},"outputs":[{"name":"stdout","text":"label\n0    27976\n2    27976\n1    27976\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# Extract aspects ","metadata":{}},{"cell_type":"code","source":"seed_aspects = {\n    'vận_chuyển': ['giao hàng', 'tiki giao', 'nhận hàng'],\n    'đóng_gói': ['đóng gói', 'bao_bì'],\n    'sản_phẩm': ['cuốn sách', 'với giá', 'chất_lượng', 'sản_phẩm'] \n}\n\ndef extract_aspects(text, seed_aspects, vocab):\n    \"\"\"\n    Trả về list các tuple: (aspect_key, aspect_phrase, start_idx, end_idx)\n    start/end là index token trong tokenized sentence (inclusive).\n    \"\"\"\n    tokenized = vocab.tokenize_corpus([text])[0]  # assumes this returns list of tokens\n    t_low = [t.lower() for t in tokenized]\n    found = []\n    for asp_key, kws in seed_aspects.items():\n        for kw in kws:\n            kw_tokens = kw.lower().split()\n            L = len(kw_tokens)\n            if L == 0:\n                continue\n            for i in range(len(t_low) - L + 1):\n                if t_low[i:i+L] == kw_tokens:\n                    phrase = \" \".join(tokenized[i:i+L])\n                    found.append((asp_key, phrase, i, i+L-1))\n                    # break to avoid duplicate matches for same kw in same sentence\n                    break\n    return tokenized, found\n\ndef get_context_string(tokens, start, end, window=3):\n    left = max(0, start - window)\n    right = min(len(tokens)-1, end + window)\n    return \" \".join(tokens[left:right+1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:21:34.685116Z","iopub.execute_input":"2025-08-30T08:21:34.685395Z","iopub.status.idle":"2025-08-30T08:21:34.692470Z","shell.execute_reply.started":"2025-08-30T08:21:34.685376Z","shell.execute_reply":"2025-08-30T08:21:34.691785Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"# 3. ML Model","metadata":{"id":"rd_WHu8v4Khn"}},{"cell_type":"markdown","source":"## 3.1 Multinomial Naive Bayes","metadata":{"id":"PkTBTlCX3BVW"}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","metadata":{"id":"Son705hwMCiM","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:36.236870Z","iopub.execute_input":"2025-08-30T08:03:36.237751Z","iopub.status.idle":"2025-08-30T08:03:36.246274Z","shell.execute_reply.started":"2025-08-30T08:03:36.237515Z","shell.execute_reply":"2025-08-30T08:03:36.245588Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\n\ntrain_sentences_tfidf = vectorizer.fit_transform(train_sentences)\ntest_sentences_tfidf = vectorizer.transform(test_sentences)","metadata":{"id":"sp40BtkkMP_o","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:38.144088Z","iopub.execute_input":"2025-08-30T08:03:38.144737Z","iopub.status.idle":"2025-08-30T08:03:40.535389Z","shell.execute_reply.started":"2025-08-30T08:03:38.144705Z","shell.execute_reply":"2025-08-30T08:03:40.534475Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model = MultinomialNB()\nmodel.fit(train_sentences_tfidf, train_labels)","metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1746180731487,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"KSIB1HwdNlgX","outputId":"5475d948-2f88-42d1-dfef-af5bd5614bb5","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:40.676297Z","iopub.execute_input":"2025-08-30T08:03:40.676549Z","iopub.status.idle":"2025-08-30T08:03:40.703810Z","shell.execute_reply.started":"2025-08-30T08:03:40.676505Z","shell.execute_reply":"2025-08-30T08:03:40.703041Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"MultinomialNB()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"pred = model.predict(test_sentences_tfidf)","metadata":{"id":"wBL3a8piNmYl","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:43.109977Z","iopub.execute_input":"2025-08-30T08:03:43.110281Z","iopub.status.idle":"2025-08-30T08:03:43.117095Z","shell.execute_reply.started":"2025-08-30T08:03:43.110251Z","shell.execute_reply":"2025-08-30T08:03:43.116507Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"print(\"Accuracy:\", accuracy_score(test_labels, pred))\nprint(\"Classification Report:\")\nprint(classification_report(test_labels, pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(test_labels, pred))","metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1746180734935,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"-ht0JEjoNqgK","outputId":"3d4445cd-f5c6-4f04-918f-bf9ffc0b85c3","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:45.267731Z","iopub.execute_input":"2025-08-30T08:03:45.268006Z","iopub.status.idle":"2025-08-30T08:03:45.284910Z","shell.execute_reply.started":"2025-08-30T08:03:45.267985Z","shell.execute_reply":"2025-08-30T08:03:45.284290Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7501142074006396\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.57      0.69      0.63      1207\n           1       0.15      0.44      0.22       555\n           2       0.97      0.78      0.87      6994\n\n    accuracy                           0.75      8756\n   macro avg       0.56      0.64      0.57      8756\nweighted avg       0.86      0.75      0.79      8756\n\nConfusion Matrix:\n[[ 836  301   70]\n [ 190  242  123]\n [ 442 1062 5490]]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"label2sen = {0: \"Tiêu cực\", 1: \"Bình thường\", 2: \"Tích cực\"} ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:07:51.254382Z","iopub.execute_input":"2025-08-30T08:07:51.254969Z","iopub.status.idle":"2025-08-30T08:07:51.258451Z","shell.execute_reply.started":"2025-08-30T08:07:51.254943Z","shell.execute_reply":"2025-08-30T08:07:51.257634Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"print(\"Chạy Naive Bayes (gõ 'thoát' để dừng).\")\nwhile True:\n    input_text = input(\"Nhập câu cần kiểm tra: \").strip()\n    if input_text.lower() == \"thoát\":\n        print(\"Chúc một ngày tốt lành !\")\n        break\n\n    # tokenization + aspect extraction\n    tokenized, aspects = extract_aspects(clean_text(input_text), seed_aspects, vocab)\n\n    if len(aspects) == 0:\n        # fallback: toàn câu\n        vec = vectorizer.transform([clean_text(input_text)])\n        pred = model.predict(vec)[0]\n        print(\"Không tìm thấy aspect. Dự đoán cảm xúc toàn câu:\", label2sen[pred], \"\\n\")\n    else:\n        print(f\"Tìm thấy {len(aspects)} aspect:\")\n        for asp_key, asp_phrase, s, e in aspects:\n            context = get_context_string(tokenized, s, e, window=3)\n            vec = vectorizer.transform([context])\n            pred = model.predict(vec)[0]\n            print(f\" - Aspect '{asp_key}' (\\\"{asp_phrase}\\\") => {label2sen[pred]} (context: {context})\")\n        print()","metadata":{"executionInfo":{"elapsed":76177,"status":"ok","timestamp":1746174096531,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"e_e0rRMPULmq","outputId":"ecf8cbaa-26d3-491d-a6bc-cc3c681b63fc","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:19:53.674914Z","iopub.execute_input":"2025-08-30T08:19:53.675194Z","iopub.status.idle":"2025-08-30T08:20:41.274155Z","shell.execute_reply.started":"2025-08-30T08:19:53.675173Z","shell.execute_reply":"2025-08-30T08:20:41.273014Z"}},"outputs":[{"name":"stdout","text":"Chạy Naive Bayes (gõ 'thoát' để dừng).\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Nhập câu cần kiểm tra:  giao hàng chậm nhưng chất lượng ổn\n"},{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 1240.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tìm thấy 2 aspect:\n - Aspect 'vận_chuyển' (\"giao hàng\") => Tiêu cực (context: giao hàng chậm nhưng chất_lượng)\n - Aspect 'sản_phẩm' (\"chất_lượng\") => Bình thường (context: hàng chậm nhưng chất_lượng ổn)\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Nhập câu cần kiểm tra:  quá tệ\n"},{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 2737.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Không tìm thấy aspect. Dự đoán cảm xúc toàn câu: Tiêu cực \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Nhập câu cần kiểm tra:  bao bì đẹp nhưng sản phẩm quá đắt \n"},{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 1154.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tìm thấy 1 aspect:\n - Aspect 'đóng_gói' (\"bao_bì\") => Tích cực (context: bao_bì đẹp nhưng sản_phẩm)\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_121/1517186089.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chạy Naive Bayes (gõ 'thoát' để dừng).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nhập câu cần kiểm tra: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"thoát\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chúc một ngày tốt lành !\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}],"execution_count":57},{"cell_type":"markdown","source":"# 4. DL Model","metadata":{"id":"y4WZDW5wu9y2"}},{"cell_type":"markdown","source":"## 4.1 Word Embedding","metadata":{"id":"-uvILOwq_SbJ"}},{"cell_type":"code","source":"!pip install torch==2.2.0 ","metadata":{"executionInfo":{"elapsed":176883,"status":"ok","timestamp":1746194015784,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"NRwtkFQ_BMNt","outputId":"74c332cc-5ead-45a3-8e0f-cd3723c0f59e","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:52.247059Z","iopub.execute_input":"2025-08-30T08:03:52.247806Z","iopub.status.idle":"2025-08-30T08:03:55.258305Z","shell.execute_reply.started":"2025-08-30T08:03:52.247776Z","shell.execute_reply":"2025-08-30T08:03:55.257328Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.11/dist-packages (2.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (4.13.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.8.93)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!pip install torchtext==0.17.0 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:03:59.178603Z","iopub.execute_input":"2025-08-30T08:03:59.178904Z","iopub.status.idle":"2025-08-30T08:04:02.325049Z","shell.execute_reply.started":"2025-08-30T08:03:59.178883Z","shell.execute_reply":"2025-08-30T08:04:02.324261Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchtext==0.17.0 in /usr/local/lib/python3.11/dist-packages (0.17.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.32.3)\nRequirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (1.26.4)\nRequirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (0.7.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (4.13.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2.2.0)\nRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext==0.17.0) (12.8.93)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0->torchtext==0.17.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtext==0.17.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtext==0.17.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchtext==0.17.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchtext==0.17.0) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->torchtext==0.17.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchtext==0.17.0) (2024.2.0)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import torch \nimport torchtext.vocab as vocab","metadata":{"executionInfo":{"elapsed":4776,"status":"ok","timestamp":1746194050798,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"KlSyq9yz_ZLe","outputId":"3e4fce0d-2897-4f0b-ad0b-cf101ad85ba1","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:04:13.483101Z","iopub.execute_input":"2025-08-30T08:04:13.483415Z","iopub.status.idle":"2025-08-30T08:04:14.824770Z","shell.execute_reply.started":"2025-08-30T08:04:13.483391Z","shell.execute_reply":"2025-08-30T08:04:14.824013Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"input_path = '/kaggle/input/vietnamese-comment/vi_word2vec.txt'\noutput_path = '/kaggle/working/vi_word2vec_reduced.txt' \nmax_lines = 100000  # Số dòng bạn muốn giữ lại ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:06:14.206198Z","iopub.execute_input":"2025-08-30T08:06:14.206808Z","iopub.status.idle":"2025-08-30T08:06:14.210555Z","shell.execute_reply.started":"2025-08-30T08:06:14.206781Z","shell.execute_reply":"2025-08-30T08:06:14.209704Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"with open(input_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', encoding='utf-8') as outfile:\n    for i, line in enumerate(infile):\n        if i > max_lines:\n            break\n        outfile.write(line) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:06:19.890338Z","iopub.execute_input":"2025-08-30T08:06:19.890645Z","iopub.status.idle":"2025-08-30T08:06:21.397615Z","shell.execute_reply.started":"2025-08-30T08:06:19.890624Z","shell.execute_reply":"2025-08-30T08:06:21.396935Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"word_embedding = vocab.Vectors(name = '/kaggle/working/vi_word2vec_reduced.txt', unk_init = torch.Tensor.normal_)\nword_embedding.vectors.shape","metadata":{"executionInfo":{"elapsed":103600,"status":"ok","timestamp":1746194158170,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"XNwfsCmxBk3K","outputId":"2d0c240f-d4d4-48c2-ffd9-c1706a04a6c5","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:06:23.126052Z","iopub.execute_input":"2025-08-30T08:06:23.126793Z","iopub.status.idle":"2025-08-30T08:06:27.741436Z","shell.execute_reply.started":"2025-08-30T08:06:23.126769Z","shell.execute_reply":"2025-08-30T08:06:27.740640Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 100000/100000 [00:04<00:00, 23131.14it/s]\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"torch.Size([100000, 100])"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"def get_vector(embeddings, word):\n    assert word in embeddings.stoi, f'*{word}* is not in the vocab!'\n    return embeddings.vectors[embeddings.stoi[word]]\n\ndef closest_words(embeddings, vector, n=10):\n    distances = [(word, torch.dist(vector, get_vector(embeddings, word)).item())\n                 for word in embeddings.itos]\n\n    return sorted(distances, key = lambda w: w[1])[:n]","metadata":{"executionInfo":{"elapsed":15471,"status":"ok","timestamp":1746194194823,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"Ug_yYagDIxD3","outputId":"e1cf4730-d8c1-4c4a-e0a4-6824f3ce1eee","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"word_vector = get_vector(word_embedding, \"Lạc_Long_Quân\")\n\nclosest_words(word_embedding, word_vector, n=20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2 Vocabulary Class","metadata":{"id":"kPhuKPoCKP4Y"}},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"TUzIsdjUI8Yv","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:06:30.352591Z","iopub.execute_input":"2025-08-30T08:06:30.353238Z","iopub.status.idle":"2025-08-30T08:06:30.356452Z","shell.execute_reply.started":"2025-08-30T08:06:30.353203Z","shell.execute_reply":"2025-08-30T08:06:30.355669Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"class Vocabulary:\n    def __init__(self):\n        self.word2id = dict()\n        self.word2id['<pad>'] = 0   # Pad Token\n        self.word2id['<unk>'] = 1   # Unknown Token\n        self.unk_id = self.word2id['<unk>']\n        self.id2word = {v: k for k, v in self.word2id.items()}\n\n    def __getitem__(self, word):\n        return self.word2id.get(word, self.unk_id)\n\n    def __contains__(self, word):\n        return word in self.word2id\n\n    def __len__(self):\n        return len(self.word2id)\n\n    def id2word(self, word_index):\n        return self.id2word[word_index]\n\n    def add(self, word):\n        if word not in self:\n            word_index = self.word2id[word] = len(self.word2id)\n            self.id2word[word_index] = word\n            return word_index\n        else:\n            return self[word]\n\n    @staticmethod\n    def tokenize_corpus(corpus):\n        print(\"Tokenize the corpus...\")\n        tokenized_corpus = list()\n        for document in tqdm(corpus):\n            tokenized_document = [word.replace(\" \", \"_\") for word in word_tokenize(document)]\n            tokenized_corpus.append(tokenized_document)\n\n        return tokenized_corpus\n\n    def corpus_to_tensor(self, corpus, is_tokenized=False):\n        if is_tokenized:\n            tokenized_corpus = corpus\n        else:\n            tokenized_corpus = self.tokenize_corpus(corpus)\n        indicies_corpus = list()\n        for document in tqdm(tokenized_corpus):\n            indicies_document = torch.tensor(list(map(lambda word: self[word], document)),\n                                             dtype=torch.int64)\n            indicies_corpus.append(indicies_document)\n\n        return indicies_corpus\n\n    def tensor_to_corpus(self, tensor):\n        corpus = list()\n        for indicies in tqdm(tensor):\n            document = list(map(lambda index: self.id2word[index.item()], indicies))\n            corpus.append(document)\n\n        return corpus\n\n    # def add_words_from_corpus(self, corpus, is_tokenized=False):\n    #     print(\"Add words from the corpus...\")\n    #     if is_tokenized:\n    #         tokenized_corpus = corpus\n    #     else:\n    #         tokenized_corpus = self.tokenize_corpus(corpus)\n    #     word_freq = Counter(chain(*tokenized_corpus))\n    #     non_singletons = [w for w in word_freq if word_freq[w] > 1]\n    #     print(f\"Number of words in the corpus: {len(word_freq)}\")\n    #     print(f\"Number of words with frequency > 1: {len(non_singletons)}\")\n    #     for word in non_singletons:\n    #         self.add(word)","metadata":{"id":"y0OKmH59JRNR","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:06:32.980706Z","iopub.execute_input":"2025-08-30T08:06:32.981243Z","iopub.status.idle":"2025-08-30T08:06:32.991256Z","shell.execute_reply.started":"2025-08-30T08:06:32.981223Z","shell.execute_reply":"2025-08-30T08:06:32.990679Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"corpus_sample = [\"Đẹp lắm mn ơi k ngờ fahasa bán alb thơ này của Lana lun, bh khó mua lắm\",\n                 \"Shop giao hàng nhanh, đóng gói hàng cẩn thận. Mặc dù sách có bé hơn mình nghĩ nhưng shop rất chu đáo. Vì mình mua gần tết nên có đc tặng thêm cả lì xì nữa. Rất đáng tiền. Mn mua ủng hộ shop nhé.\",\n                 \"lần đầu mua nhưng ok lắm luôn sắp tết nên đc tặng tập lì xì sách nhỏ nhưng bọc hộp đầy đủ đặc biệt tặng cả voucher cho lần sau chỉ có cái sách được bọc bằng màng thực phẩm\"]\n\nVocabulary.tokenize_corpus(corpus_sample)","metadata":{"executionInfo":{"elapsed":753,"status":"ok","timestamp":1746194235139,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"qPuoNxT8Jssh","outputId":"60fa012f-5e6c-4213-fa79-da45b15fd327","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:06:44.213448Z","iopub.execute_input":"2025-08-30T08:06:44.213974Z","iopub.status.idle":"2025-08-30T08:06:44.397254Z","shell.execute_reply.started":"2025-08-30T08:06:44.213951Z","shell.execute_reply":"2025-08-30T08:06:44.396632Z"}},"outputs":[{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 17.18it/s]\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"[['Đẹp',\n  'lắm',\n  'mn',\n  'ơi',\n  'k',\n  'ngờ',\n  'fahasa',\n  'bán',\n  'alb_thơ',\n  'này',\n  'của',\n  'Lana_lun',\n  ',',\n  'bh',\n  'khó',\n  'mua',\n  'lắm'],\n ['Shop',\n  'giao',\n  'hàng',\n  'nhanh',\n  ',',\n  'đóng_gói',\n  'hàng',\n  'cẩn_thận',\n  '.',\n  'Mặc_dù',\n  'sách',\n  'có',\n  'bé',\n  'hơn',\n  'mình',\n  'nghĩ',\n  'nhưng',\n  'shop',\n  'rất',\n  'chu_đáo',\n  '.',\n  'Vì',\n  'mình',\n  'mua',\n  'gần',\n  'tết',\n  'nên',\n  'có',\n  'đc',\n  'tặng',\n  'thêm',\n  'cả',\n  'lì_xì',\n  'nữa',\n  '.',\n  'Rất',\n  'đáng',\n  'tiền',\n  '.',\n  'Mn',\n  'mua',\n  'ủng_hộ',\n  'shop',\n  'nhé',\n  '.'],\n ['lần',\n  'đầu',\n  'mua',\n  'nhưng',\n  'ok',\n  'lắm',\n  'luôn',\n  'sắp',\n  'tết',\n  'nên',\n  'đc',\n  'tặng',\n  'tập_lì',\n  'xì',\n  'sách',\n  'nhỏ',\n  'nhưng',\n  'bọc_hộp',\n  'đầy_đủ',\n  'đặc_biệt',\n  'tặng',\n  'cả',\n  'voucher',\n  'cho',\n  'lần',\n  'sau',\n  'chỉ',\n  'có',\n  'cái',\n  'sách',\n  'được',\n  'bọc',\n  'bằng',\n  'màng',\n  'thực_phẩm']]"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"vocab = Vocabulary()\n\n# create vocabulary from pretrained word2vec\nwords_list = list(word_embedding.stoi.keys())\nfor word in words_list:\n    vocab.add(word)\n\n# test the vocabulary\ntensor = vocab.corpus_to_tensor(corpus_sample)\ncorpus = vocab.tensor_to_corpus(tensor)\n\" \".join(corpus[0])","metadata":{"executionInfo":{"elapsed":1427,"status":"ok","timestamp":1746194239758,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"CN5owFxXJ0ad","outputId":"588e75fb-406f-4322-dea2-c730afa3b7d3","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:06:50.104185Z","iopub.execute_input":"2025-08-30T08:06:50.104435Z","iopub.status.idle":"2025-08-30T08:06:50.175772Z","shell.execute_reply.started":"2025-08-30T08:06:50.104418Z","shell.execute_reply":"2025-08-30T08:06:50.175144Z"}},"outputs":[{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 526.00it/s]\n100%|██████████| 3/3 [00:00<00:00, 14298.76it/s]\n100%|██████████| 3/3 [00:00<00:00, 3855.06it/s]\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'Đẹp lắm <unk> ơi k ngờ <unk> bán <unk> này của <unk> , <unk> khó mua lắm'"},"metadata":{}}],"execution_count":43},{"cell_type":"markdown","source":"## 4.3 CommentDataset Class","metadata":{"id":"AUU-I4_4KgNQ"}},{"cell_type":"code","source":"from scipy.linalg.special_matrices import dft\nfrom torch.utils.data import Dataset","metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1746194243323,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"ANHI2NEuKB7U","outputId":"7240a3da-1e92-40be-9c1e-ad707d4baa3a","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:22:07.890812Z","iopub.execute_input":"2025-08-30T08:22:07.891542Z","iopub.status.idle":"2025-08-30T08:22:07.895383Z","shell.execute_reply.started":"2025-08-30T08:22:07.891502Z","shell.execute_reply":"2025-08-30T08:22:07.894542Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_121/4042193658.py:1: DeprecationWarning: Please import `dft` from the `scipy.linalg` namespace; the `scipy.linalg.special_matrices` namespace is deprecated and will be removed in SciPy 2.0.0.\n  from scipy.linalg.special_matrices import dft\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"class CommentDataset(Dataset):\n\n    def __init__(self, vocab, df, tokenized_fpath=None):\n        self.vocab = vocab\n        self.pad_idx = vocab[\"<pad>\"]\n        df = df\n        self.sentiments_list = list(df.label)\n        self.reviews_list = list(df.text)\n\n        sentiments_type = list(set(self.sentiments_list))\n        sentiments_type.sort()\n\n        self.sentiment2id = {sentiment: i for i, sentiment in enumerate(sentiments_type)}\n\n        if tokenized_fpath:\n            self.tokenized_reviews = torch.load(tokenized_fpath)\n        else:\n            self.tokenized_reviews = self.vocab.tokenize_corpus(self.reviews_list)\n\n        self.tensor_data = self.vocab.corpus_to_tensor(self.tokenized_reviews, is_tokenized=True)\n        self.tensor_label = torch.tensor([self.sentiment2id[sentiment] for sentiment in self.sentiments_list],\n                                         dtype=torch.float64)\n\n        self.tensor_data, self.tensor_label = zip(*[(data, label) for data, label in zip(self.tensor_data, self.tensor_label) if len(data) > 0])\n        self.tensor_data = list(self.tensor_data)\n        self.tensor_label = torch.tensor(self.tensor_label, dtype=torch.float64) # Convert back to tensor\n\n    def __len__(self):\n        return len(self.tensor_data)\n\n    def __getitem__(self, idx):\n        return self.tensor_data[idx], self.tensor_label[idx]\n\n    def collate_fn(self, examples):\n        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n\n        reviews = [e[0] for e in examples]\n        reviews = torch.nn.utils.rnn.pad_sequence(reviews,\n                                                  batch_first=False,\n                                                  padding_value=self.pad_idx)\n        reviews_lengths = torch.tensor([len(e[0]) for e in examples])\n        sentiments = torch.tensor([e[1] for e in examples])\n\n        return {\"reviews\": (reviews, reviews_lengths), \"sentiments\": sentiments}","metadata":{"id":"kuT630Y0KvBm","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:22:10.775120Z","iopub.execute_input":"2025-08-30T08:22:10.775752Z","iopub.status.idle":"2025-08-30T08:22:10.804145Z","shell.execute_reply.started":"2025-08-30T08:22:10.775729Z","shell.execute_reply":"2025-08-30T08:22:10.803583Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"valid_df = train_balanced.sample(frac=0.2, random_state=42).reset_index()\ntrain_df = train_balanced.drop(valid_df.index).reset_index()\ntest_df = pd.DataFrame({\n    'text': test_sentences,\n    'label': test_labels\n}).reset_index()","metadata":{"id":"ceP8RzYJLSbF","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:22:14.497475Z","iopub.execute_input":"2025-08-30T08:22:14.497781Z","iopub.status.idle":"2025-08-30T08:22:14.517599Z","shell.execute_reply.started":"2025-08-30T08:22:14.497760Z","shell.execute_reply":"2025-08-30T08:22:14.516574Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"valid_df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:22:16.758016Z","iopub.execute_input":"2025-08-30T08:22:16.758290Z","iopub.status.idle":"2025-08-30T08:22:16.765278Z","shell.execute_reply.started":"2025-08-30T08:22:16.758268Z","shell.execute_reply":"2025-08-30T08:22:16.764436Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"label\n0    5644\n2    5588\n1    5554\nName: count, dtype: int64"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":" valid_df.drop(columns=['index'], inplace=True)\n train_df.drop(columns=['index'], inplace=True)\n test_df.drop(columns=['index'], inplace=True)","metadata":{"id":"yXs1JIFeL5V9","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:22:19.751898Z","iopub.execute_input":"2025-08-30T08:22:19.752585Z","iopub.status.idle":"2025-08-30T08:22:19.769914Z","shell.execute_reply.started":"2025-08-30T08:22:19.752558Z","shell.execute_reply":"2025-08-30T08:22:19.769143Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"train_dataset = CommentDataset(vocab, train_df)\nvalid_dataset = CommentDataset(vocab, valid_df)\ntest_dataset = CommentDataset(vocab, test_df)","metadata":{"executionInfo":{"elapsed":136089,"status":"ok","timestamp":1746194391233,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"bm8J8t-XMGUW","outputId":"6317c80d-6e3d-4d86-c908-544bb9f8b60b","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:22:22.477722Z","iopub.execute_input":"2025-08-30T08:22:22.478212Z","iopub.status.idle":"2025-08-30T08:25:06.069089Z","shell.execute_reply.started":"2025-08-30T08:22:22.478187Z","shell.execute_reply":"2025-08-30T08:25:06.068475Z"}},"outputs":[{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 67142/67142 [01:52<00:00, 599.10it/s]\n100%|██████████| 67142/67142 [00:01<00:00, 54247.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16786/16786 [00:32<00:00, 521.58it/s]\n100%|██████████| 16786/16786 [00:00<00:00, 71136.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 8756/8756 [00:17<00:00, 512.44it/s]\n100%|██████████| 8756/8756 [00:00<00:00, 59906.41it/s]\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"## 4.4 Create DataLoader from IMDBDataset","metadata":{"id":"0dJyD-NkN6qR"}},{"cell_type":"code","source":"from torch.utils.data import DataLoader","metadata":{"id":"ok2-GZhwNvWs","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:08.771041Z","iopub.execute_input":"2025-08-30T08:25:08.771323Z","iopub.status.idle":"2025-08-30T08:25:08.774810Z","shell.execute_reply.started":"2025-08-30T08:25:08.771291Z","shell.execute_reply":"2025-08-30T08:25:08.774170Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"batch_size = 32\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, collate_fn=train_dataset.collate_fn)\nvalid_dataloader = DataLoader(valid_dataset, shuffle=True, batch_size=batch_size, collate_fn=valid_dataset.collate_fn)\ntest_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size, collate_fn=test_dataset.collate_fn)","metadata":{"id":"Ry9tY3fVOFR9","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:11.407786Z","iopub.execute_input":"2025-08-30T08:25:11.408520Z","iopub.status.idle":"2025-08-30T08:25:11.413272Z","shell.execute_reply.started":"2025-08-30T08:25:11.408493Z","shell.execute_reply":"2025-08-30T08:25:11.412454Z"}},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":"## 4.5 RNN Model","metadata":{"id":"DvsY8fMg3KUY"}},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"id":"sDEYcDrgOHe5","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:14.525601Z","iopub.execute_input":"2025-08-30T08:25:14.526342Z","iopub.status.idle":"2025-08-30T08:25:14.529609Z","shell.execute_reply.started":"2025-08-30T08:25:14.526316Z","shell.execute_reply":"2025-08-30T08:25:14.528835Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers,\n                 bidirectional, dropout, pad_idx, n_classes):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n        self.rnn = nn.LSTM(\n            embedding_dim,\n            hidden_dim,\n            num_layers=n_layers,\n            bidirectional=bidirectional,\n            dropout=dropout if n_layers > 1 else 0\n        )\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), n_classes)\n\n    def forward(self, text, text_lengths):\n        embedded = self.dropout(self.embedding(text))\n        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n            embedded, text_lengths.to('cpu'), enforce_sorted=False\n        )\n        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n        if self.rnn.bidirectional:\n            hidden = self.dropout(torch.cat((hidden[-2], hidden[-1]), dim=1))\n        else:\n            hidden = self.dropout(hidden[-1])\n        return self.fc(hidden)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:17.415825Z","iopub.execute_input":"2025-08-30T08:25:17.416589Z","iopub.status.idle":"2025-08-30T08:25:17.422370Z","shell.execute_reply.started":"2025-08-30T08:25:17.416556Z","shell.execute_reply":"2025-08-30T08:25:17.421842Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"input_dim = word_embedding.vectors.shape[0] \nembedding_dim = 100\nhidden_dim = 8  \nn_layers = 2\nbidirectional = False \ndropout = 0.3 \npad_idx = vocab[\"<pad>\"]\nunk_idx = vocab[\"<unk>\"]\nn_classes = 3  # positive, neutral, negative\n\nmodel = RNN(input_dim, embedding_dim, hidden_dim, n_layers, bidirectional, dropout, pad_idx, n_classes)","metadata":{"id":"4_4gdqbc77CI","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:21.041627Z","iopub.execute_input":"2025-08-30T08:25:21.042149Z","iopub.status.idle":"2025-08-30T08:25:21.134785Z","shell.execute_reply.started":"2025-08-30T08:25:21.042129Z","shell.execute_reply":"2025-08-30T08:25:21.134203Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"model.embedding.weight.data.copy_(word_embedding.vectors)\nmodel.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\nmodel.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)","metadata":{"id":"syPlzxAlPq2f","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:23.655825Z","iopub.execute_input":"2025-08-30T08:25:23.656384Z","iopub.status.idle":"2025-08-30T08:25:23.664287Z","shell.execute_reply.started":"2025-08-30T08:25:23.656360Z","shell.execute_reply":"2025-08-30T08:25:23.663547Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"executionInfo":{"elapsed":40,"status":"ok","timestamp":1746194406406,"user":{"displayName":"Viet Tranhuu","userId":"08791169309344190178"},"user_tz":-420},"id":"dI2rLTSjP2Wf","outputId":"97310f26-c1da-48f7-b70f-385aca59b885","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:26.115113Z","iopub.execute_input":"2025-08-30T08:25:26.115386Z","iopub.status.idle":"2025-08-30T08:25:26.120185Z","shell.execute_reply.started":"2025-08-30T08:25:26.115364Z","shell.execute_reply":"2025-08-30T08:25:26.119291Z"}},"outputs":[{"name":"stdout","text":"The model has 10,004,123 trainable parameters\n","output_type":"stream"}],"execution_count":71},{"cell_type":"markdown","source":"## 4.6 Train the model","metadata":{"id":"-MF9RoIfP9ag"}},{"cell_type":"code","source":"import torch.optim as optim\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score","metadata":{"id":"tPTimkkcQFt0","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:28.531571Z","iopub.execute_input":"2025-08-30T08:25:28.531843Z","iopub.status.idle":"2025-08-30T08:25:28.535566Z","shell.execute_reply.started":"2025-08-30T08:25:28.531822Z","shell.execute_reply":"2025-08-30T08:25:28.534844Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss().to(device) \n\nmodel = model.to(device)","metadata":{"id":"sSRqCavQP6aP","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:30.897005Z","iopub.execute_input":"2025-08-30T08:25:30.897496Z","iopub.status.idle":"2025-08-30T08:25:33.389863Z","shell.execute_reply.started":"2025-08-30T08:25:30.897470Z","shell.execute_reply":"2025-08-30T08:25:33.389042Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"def compute_metrics_1(preds, labels):\n    acc = accuracy_score(labels, preds)\n    return acc ","metadata":{"id":"ur6s3FBBQIb4","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:33.892491Z","iopub.execute_input":"2025-08-30T08:25:33.892996Z","iopub.status.idle":"2025-08-30T08:25:33.897013Z","shell.execute_reply.started":"2025-08-30T08:25:33.892972Z","shell.execute_reply":"2025-08-30T08:25:33.896407Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"def compute_metrics_2(preds, labels):\n    acc = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        labels, preds, average='weighted', zero_division=0\n    )\n    return acc, precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:36.396161Z","iopub.execute_input":"2025-08-30T08:25:36.396458Z","iopub.status.idle":"2025-08-30T08:25:36.400922Z","shell.execute_reply.started":"2025-08-30T08:25:36.396436Z","shell.execute_reply":"2025-08-30T08:25:36.399956Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"def train(model, dataloader, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    all_preds, all_labels = [], []\n\n    for batch in dataloader:\n        optimizer.zero_grad()\n        reviews, lengths = batch['reviews']\n        reviews, lengths = reviews.to(device), lengths.to(device)\n        logits = model(reviews, lengths)\n        labels = batch['sentiments'].long().squeeze(-1).to(device)\n\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n\n        preds = logits.argmax(dim=1).cpu().tolist()\n        all_preds.extend(preds)\n        all_labels.extend(labels.cpu().tolist())\n\n    acc = compute_metrics_1(all_preds, all_labels)\n    return epoch_loss / len(dataloader), acc ","metadata":{"id":"TSfvzJqKQM47","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:38.685519Z","iopub.execute_input":"2025-08-30T08:25:38.686264Z","iopub.status.idle":"2025-08-30T08:25:38.691421Z","shell.execute_reply.started":"2025-08-30T08:25:38.686241Z","shell.execute_reply":"2025-08-30T08:25:38.690745Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"def evaluate_1(model, dataloader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            reviews, lengths = batch['reviews']\n            reviews, lengths = reviews.to(device), lengths.to(device)\n            logits = model(reviews, lengths)\n            labels = batch['sentiments'].long().squeeze(-1).to(device)\n\n            loss = criterion(logits, labels)\n            epoch_loss += loss.item()\n\n            preds = logits.argmax(dim=1).cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().tolist())\n\n    acc = compute_metrics_1(all_preds, all_labels)\n    return epoch_loss / len(dataloader), acc","metadata":{"id":"7GOYp5OIQP6j","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:47.879883Z","iopub.execute_input":"2025-08-30T08:25:47.880168Z","iopub.status.idle":"2025-08-30T08:25:47.885458Z","shell.execute_reply.started":"2025-08-30T08:25:47.880145Z","shell.execute_reply":"2025-08-30T08:25:47.884565Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"def evaluate_2(model, dataloader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            reviews, lengths = batch['reviews']\n            reviews, lengths = reviews.to(device), lengths.to(device)\n            logits = model(reviews, lengths)\n            labels = batch['sentiments'].long().squeeze(-1).to(device)\n\n            loss = criterion(logits, labels)\n            epoch_loss += loss.item()\n\n            preds = logits.argmax(dim=1).cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().tolist())\n\n    acc, precision, recall, f1 = compute_metrics_2(all_preds, all_labels)\n    return epoch_loss / len(dataloader), acc, precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:52.037081Z","iopub.execute_input":"2025-08-30T08:25:52.037361Z","iopub.status.idle":"2025-08-30T08:25:52.043061Z","shell.execute_reply.started":"2025-08-30T08:25:52.037340Z","shell.execute_reply":"2025-08-30T08:25:52.042211Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"import time","metadata":{"id":"3IbqwPJuQZ2d","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:55.233649Z","iopub.execute_input":"2025-08-30T08:25:55.234159Z","iopub.status.idle":"2025-08-30T08:25:55.237665Z","shell.execute_reply.started":"2025-08-30T08:25:55.234137Z","shell.execute_reply":"2025-08-30T08:25:55.236956Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"id":"h6CMYJsaQSpW","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:25:57.432010Z","iopub.execute_input":"2025-08-30T08:25:57.432754Z","iopub.status.idle":"2025-08-30T08:25:57.436242Z","shell.execute_reply.started":"2025-08-30T08:25:57.432730Z","shell.execute_reply":"2025-08-30T08:25:57.435711Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"n_epochs = 5\n\nbest_valid_loss = float(\"inf\")\n\nfor epoch in range(n_epochs):\n    start_time = time.time()\n\n    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, device)\n    valid_loss, valid_acc = evaluate_1(model, valid_dataloader, criterion, device)\n\n    end_time = time.time()\n\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'model.pt')\n\n    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n    print(f\"  Train - loss: {train_loss:.3f}| acc: {train_acc:.2f}\")\n    print(f\"  Valid - loss: {valid_loss:.3f}| acc: {valid_acc:.2f}\")","metadata":{"id":"zASLf1b3QcQi","outputId":"9d7d9954-7661-4a67-b0ac-32acfa4f6104","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:26:00.136243Z","iopub.execute_input":"2025-08-30T08:26:00.136923Z","iopub.status.idle":"2025-08-30T08:28:46.115545Z","shell.execute_reply.started":"2025-08-30T08:26:00.136901Z","shell.execute_reply":"2025-08-30T08:28:46.114594Z"}},"outputs":[{"name":"stdout","text":"Epoch: 01 | Time: 0m 33s\n  Train - loss: 0.748| acc: 0.66\n  Valid - loss: 0.478| acc: 0.83\nEpoch: 02 | Time: 0m 32s\n  Train - loss: 0.477| acc: 0.83\n  Valid - loss: 0.329| acc: 0.89\nEpoch: 03 | Time: 0m 32s\n  Train - loss: 0.359| acc: 0.88\n  Valid - loss: 0.234| acc: 0.92\nEpoch: 04 | Time: 0m 33s\n  Train - loss: 0.291| acc: 0.91\n  Valid - loss: 0.183| acc: 0.95\nEpoch: 05 | Time: 0m 33s\n  Train - loss: 0.241| acc: 0.93\n  Valid - loss: 0.159| acc: 0.95\n","output_type":"stream"}],"execution_count":82},{"cell_type":"markdown","source":"## 4.7 Test the model ","metadata":{}},{"cell_type":"code","source":"test_loss, test_acc, test_prec, test_rec, test_f1 = evaluate_2(model, test_dataloader, criterion, device)\n\nprint(f\"Test - loss: {test_loss:.3f}| acc: {test_acc:.2f}| prec: {test_prec:.2f}| rec: {test_rec:.2f}| f1: {test_f1:.2f}\")","metadata":{"id":"O1H6T20mUDgD","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:30:29.641188Z","iopub.execute_input":"2025-08-30T08:30:29.642117Z","iopub.status.idle":"2025-08-30T08:30:30.829984Z","shell.execute_reply.started":"2025-08-30T08:30:29.642086Z","shell.execute_reply":"2025-08-30T08:30:30.829233Z"}},"outputs":[{"name":"stdout","text":"Test - loss: 0.692| acc: 0.82| prec: 0.86| rec: 0.82| f1: 0.84\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"import torch.nn.functional as F ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:30:33.565784Z","iopub.execute_input":"2025-08-30T08:30:33.566358Z","iopub.status.idle":"2025-08-30T08:30:33.569539Z","shell.execute_reply.started":"2025-08-30T08:30:33.566337Z","shell.execute_reply":"2025-08-30T08:30:33.568871Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"def predict_sentiment(model, sentence, vocab, device, label_mapping=None):\n    model.eval()\n\n    # Convert sentence to tensor of token indices\n    corpus = [sentence]\n    tensor = vocab.corpus_to_tensor(corpus)[0].to(device)        # [seq_len]\n    tensor = tensor.unsqueeze(1)                                 # [seq_len, 1]\n    length_tensor = torch.LongTensor([tensor.size(0)]).to(device)\n\n    # Forward pass\n    with torch.no_grad():\n        logits = model(tensor, length_tensor).squeeze(0)         # [n_classes]\n        probs = F.softmax(logits, dim=-1)                       # [n_classes]\n\n    # Predicted class index and optional label name\n    pred_idx = probs.argmax().item()\n    pred_label = label_mapping[pred_idx] if label_mapping is not None else str(pred_idx)\n\n    # Return index, label, and full probability distribution\n    return pred_label, probs.cpu().tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:30:36.352395Z","iopub.execute_input":"2025-08-30T08:30:36.353162Z","iopub.status.idle":"2025-08-30T08:30:36.358307Z","shell.execute_reply.started":"2025-08-30T08:30:36.353138Z","shell.execute_reply":"2025-08-30T08:30:36.357695Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"label_map = {0: 'tiêu cực', 1: 'bình thường', 2: 'tích cực'}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:32:26.249749Z","iopub.execute_input":"2025-08-30T08:32:26.250329Z","iopub.status.idle":"2025-08-30T08:32:26.253865Z","shell.execute_reply.started":"2025-08-30T08:32:26.250301Z","shell.execute_reply":"2025-08-30T08:32:26.253052Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"print(\"Chạy BiLSTM (gõ 'thoát' để dừng).\")\nwhile True:\n    input_text = input(\"Nhập câu cần kiểm tra: \").strip()\n    if input_text.lower() == \"thoát\":\n        print(\"Chúc một ngày tốt lành!\")\n        break\n\n    tokenized, aspects = extract_aspects(clean_text(input_text), seed_aspects, vocab)\n\n    if len(aspects) == 0:\n        # fallback: toàn câu\n        sent, probs = predict_sentiment(model=model,\n                                        sentence=clean_text(input_text),\n                                        vocab=vocab,\n                                        device=device,\n                                        label_mapping=label_map)\n        print(f\"Dự đoán cảm xúc toàn câu: {sent}\\n\")\n    else:\n        print(f\"Tìm thấy {len(aspects)} aspect:\")\n        for asp_key, asp_phrase, s, e in aspects:\n            context_tokens = tokenized  # we already have tokens; build small window\n            context = get_context_string(context_tokens, s, e, window=3)\n            sent, probs = predict_sentiment(model=model,\n                                            sentence=context,\n                                            vocab=vocab,\n                                            device=device,\n                                            label_mapping=label_map)\n            print(f\" - Aspect '{asp_key}' (\\\"{asp_phrase}\\\") → {sent} (context: {context})\")\n        print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T08:32:31.830371Z","iopub.execute_input":"2025-08-30T08:32:31.830643Z","iopub.status.idle":"2025-08-30T08:32:52.972811Z","shell.execute_reply.started":"2025-08-30T08:32:31.830625Z","shell.execute_reply":"2025-08-30T08:32:52.972186Z"}},"outputs":[{"name":"stdout","text":"Chạy BiLSTM (gõ 'thoát' để dừng).\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Nhập câu cần kiểm tra:  chất lượng tốt, giao hàng nhanh\n"},{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 1331.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tìm thấy 2 aspect:\nTokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 1926.64it/s]\n100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]\n","output_type":"stream"},{"name":"stdout","text":" - Aspect 'vận_chuyển' (\"giao hàng\") → tích cực (context: chất_lượng tốt giao hàng nhanh)\nTokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 2465.79it/s]\n100%|██████████| 1/1 [00:00<00:00, 8289.14it/s]\n","output_type":"stream"},{"name":"stdout","text":" - Aspect 'sản_phẩm' (\"chất_lượng\") → tích cực (context: chất_lượng tốt giao hàng)\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Nhập câu cần kiểm tra:  quá ok\n"},{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 2912.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tokenize the corpus...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 3238.84it/s]\n100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dự đoán cảm xúc toàn câu: tích cực\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Nhập câu cần kiểm tra:  thoát\n"},{"name":"stdout","text":"Chúc một ngày tốt lành!\n","output_type":"stream"}],"execution_count":89}]}
